{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importaci√≥n de dependencias y configuraci√≥n inicial.**\n",
    "\n",
    "Se instalan y cargan las librer√≠as necesarias para el ajuste fino de modelos LLM (LLaMA‚ÄØ3, Qwen‚ÄØ2 y Foundation‚ÄëSec‚ÄØ8B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 37480,
     "status": "ok",
     "timestamp": 1760995211899,
     "user": {
      "displayName": "Javier Moreno",
      "userId": "15898376622721324964"
     },
     "user_tz": 300
    },
    "id": "h83VQgKWIV_9",
    "outputId": "028b7027-2caf-4c48-d5f5-2efe8e559172",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "üöÄ ETAPA C3: BASELINE COLAB - SETUP COMPLETADO\n",
      "üìÅ Base path: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection\n",
      "‚úÖ Estructura de folders creada\n",
      "\n",
      "üì¶ VERIFICANDO ARTEFACTOS EN DRIVE:\n",
      "   ‚úÖ balanced_evaluation_dataset.csv (0.0 MB)\n",
      "   ‚úÖ baseline_local_gguf_qbr_llama_100samples_20251003_134445.jsonl (0.1 MB)\n",
      "   ‚úÖ colab_complete_stratified_package_20251003_162517.json (0.0 MB)\n",
      "   ‚úÖ complete_validation_qbr_llama.jsonl (0.1 MB)\n",
      "   ‚úÖ complete_validation_qwen_1.5_7b_chat.jsonl (0.1 MB)\n",
      "   ‚úÖ enriched_blind_qbr_llama.jsonl (0.0 MB)\n",
      "   ‚úÖ enriched_blind_qwen_1.5_7b_chat.jsonl (0.0 MB)\n",
      "   ‚úÖ evaluation_final_10samples_from_test_20251003_220605.json (0.0 MB)\n",
      "   ‚úÖ expanded_validation_dataset_real_scores_20251003_114736.json (0.2 MB)\n",
      "   ‚úÖ fine_tuned_evaluation_stratified_10samples_20251003_162517.json (0.0 MB)\n",
      "   ‚úÖ fine_tuning_stratified_test_real_scores_20251003_162517.jsonl (24.3 MB)\n",
      "   ‚úÖ fine_tuning_stratified_train_real_scores_20251003_162517.jsonl (113.3 MB)\n",
      "   ‚úÖ fine_tuning_stratified_val_real_scores_20251003_162517.jsonl (24.3 MB)\n",
      "   ‚úÖ test.csv (384.6 MB)\n",
      "   ‚úÖ test_interpretation_metadata.csv (68.4 MB)\n",
      "   ‚úÖ tranad_plus_detections_final_interpreted.csv (12.6 MB)\n",
      "   ‚úÖ validator_metrics_robust_20251001_190906.csv (0.0 MB)\n",
      "   ‚úÖ validator_metrics_robust_20251001_194312.csv (0.0 MB)\n",
      "üíæ Setup guardado: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/checkpoints/C3_setup_20251020_212011.json\n",
      "[C3_SETUP_COMPLETE] ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 1: SETUP Y MONTAJE DE DRIVE ===\n",
    "\"\"\"\n",
    "ETAPA C3: BASELINE COLAB - MODELOS FULL PRECISION\n",
    "Evaluaci√≥n de Llama-3-8B y Qwen1.5-7B como validadores\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Montar Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Configuraci√≥n de paths\n",
    "BASE_PATH = '/content/drive/MyDrive/TFM_CIC_Anomaly_Detection'\n",
    "DATA_PATH = f'{BASE_PATH}/01_data_input'\n",
    "BASELINE_PATH = f'{BASE_PATH}/02_baseline_colab'\n",
    "CHECKPOINT_PATH = f'{BASELINE_PATH}/checkpoints'\n",
    "\n",
    "# Crear estructura si no existe\n",
    "os.makedirs(BASELINE_PATH, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "os.makedirs(f'{BASELINE_PATH}/llama_3_8b/responses', exist_ok=True)\n",
    "os.makedirs(f'{BASELINE_PATH}/qwen_1_5_7b/responses', exist_ok=True)\n",
    "os.makedirs(f'{BASELINE_PATH}/comparison_results', exist_ok=True)\n",
    "\n",
    "print(\"üöÄ ETAPA C3: BASELINE COLAB - SETUP COMPLETADO\")\n",
    "print(f\"üìÅ Base path: {BASE_PATH}\")\n",
    "print(f\"‚úÖ Estructura de folders creada\")\n",
    "\n",
    "# Verificar artefactos disponibles\n",
    "print(f\"\\nüì¶ VERIFICANDO ARTEFACTOS EN DRIVE:\")\n",
    "data_files = os.listdir(DATA_PATH)\n",
    "for file in sorted(data_files):\n",
    "    file_size = os.path.getsize(f\"{DATA_PATH}/{file}\") / (1024*1024)  # MB\n",
    "    print(f\"   ‚úÖ {file} ({file_size:.1f} MB)\")\n",
    "\n",
    "# Guardar configuraci√≥n inicial\n",
    "setup_config = {\n",
    "    'setup_timestamp': datetime.now().isoformat(),\n",
    "    'base_path': BASE_PATH,\n",
    "    'available_artifacts': data_files,\n",
    "    'target_models': [\n",
    "        'meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "        'Qwen/Qwen1.5-7B-Chat'\n",
    "    ],\n",
    "    'evaluation_approach': 'validation_with_technical_logs',\n",
    "    'dataset_size': 10,  # 5 THREATS + 5 BENIGN\n",
    "    'stage': 'C3_baseline_colab_setup'\n",
    "}\n",
    "\n",
    "setup_path = f\"{CHECKPOINT_PATH}/C3_setup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(setup_path, 'w') as f:\n",
    "    json.dump(setup_config, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Setup guardado: {setup_path}\")\n",
    "print(f\"[C3_SETUP_COMPLETE] ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importaci√≥n de dependencias y configuraci√≥n inicial.**\n",
    "\n",
    "Se instalan y cargan las librer√≠as necesarias para el ajuste fino de modelos LLM (LLaMA‚ÄØ3, Qwen‚ÄØ2 y Foundation‚ÄëSec‚ÄØ8B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7748,
     "status": "ok",
     "timestamp": 1760995251083,
     "user": {
      "displayName": "Javier Moreno",
      "userId": "15898376622721324964"
     },
     "user_tz": 300
    },
    "id": "g1bBd19ZLVUR",
    "outputId": "f7d168e6-bcc7-40f5-d9c5-16aca2fe989f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß RECREANDO DATASET BALANCEADO CORRECTO EN COLAB\n",
      "======================================================================\n",
      "‚úÖ Metadatos completos: (418242, 10)\n",
      "üìä Distribuci√≥n completa disponible: {'BENIGN': np.int64(393092), 'DDoS': np.int64(24916), 'PortScan': np.int64(234)}\n",
      "\n",
      "üéØ SELECCIONANDO DATASET BALANCEADO DESDE METADATOS:\n",
      "   ‚úÖ DDoS: 3 muestras seleccionadas\n",
      "   ‚úÖ PortScan: 2 muestras seleccionadas\n",
      "   ‚úÖ BENIGN: 5 muestras seleccionadas\n",
      "üìä Total muestras balanceadas: 10\n",
      "üìã Distribuci√≥n final: {'DDoS': 3, 'PortScan': 2, 'BENIGN': 5}\n",
      "üéØ Balance de validaci√≥n: {'CONFIRMED': 5, 'DISCARDED': 5}\n",
      "\n",
      "üìù PREPARANDO PROMPTS DE VALIDACI√ìN:\n",
      "‚úÖ 10 prompts de validaci√≥n creados\n",
      "üìä Balance final de validaci√≥n: {'CONFIRMED': 5, 'DISCARDED': 5}\n",
      "üìã Balance por tipo original: {'DDoS': 3, 'PortScan': 2, 'BENIGN': 5}\n",
      "üíæ Dataset balanceado correcto: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/colab_validation_dataset_balanced_corrected.json\n",
      "üíæ Checkpoint: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/checkpoints/C3_corrected_dataset_20251020_212050.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ DATASET BALANCEADO CORRECTO CREADO\n",
      "‚úÖ DDoS: 3 muestras\n",
      "‚úÖ PortScan: 2 muestras\n",
      "‚úÖ BENIGN: 5 muestras\n",
      "‚úÖ Balance validaci√≥n: CONFIRMED=5, DISCARDED=5\n",
      "======================================================================\n",
      "[C3_CORRECTED_DATASET_READY] ‚úÖ\n",
      "üöÄ Dataset id√©ntico al local - listo para evaluaci√≥n de modelos full precision\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 2 CORREGIDA: CREAR DATASET BALANCEADO CORRECTO ===\n",
    "\"\"\"\n",
    "Recrear dataset balanceado id√©ntico al local: 3 DDoS + 2 PortScan + 5 BENIGN\n",
    "INDEPENDIENTE - Solo usa Drive\n",
    "\"\"\"\n",
    "# ---------- Fijaci√≥n de semilla para reproducibilidad ----------\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "BASE_PATH = '/content/drive/MyDrive/TFM_CIC_Anomaly_Detection'\n",
    "DATA_PATH = f'{BASE_PATH}/01_data_input'\n",
    "BASELINE_PATH = f'{BASE_PATH}/02_baseline_colab'\n",
    "CHECKPOINT_PATH = f'{BASELINE_PATH}/checkpoints'\n",
    "\n",
    "print(\"üîß RECREANDO DATASET BALANCEADO CORRECTO EN COLAB\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# === CARGAR DATASETS COMPLETOS ===\n",
    "try:\n",
    "    # Acceder al test completo para encontrar DDoS\n",
    "\n",
    "\n",
    "    test_meta = pd.read_csv(f\"{DATA_PATH}/test_interpretation_metadata.csv\")\n",
    "    print(f\"‚úÖ Metadatos completos: {test_meta.shape}\")\n",
    "\n",
    "    # Verificar distribuci√≥n completa\n",
    "    full_dist = test_meta['original_label'].value_counts()\n",
    "    print(f\"üìä Distribuci√≥n completa disponible: {dict(full_dist)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# === SELECCIONAR DATASET BALANCEADO DESDE METADATOS ===\n",
    "print(f\"\\nüéØ SELECCIONANDO DATASET BALANCEADO DESDE METADATOS:\")\n",
    "\n",
    "np.random.seed(42)  # Misma semilla que local\n",
    "balanced_colab_samples = []\n",
    "\n",
    "# 1. DDoS - 3 muestras\n",
    "ddos_data = test_meta[test_meta['original_label'] == 'DDoS']\n",
    "if len(ddos_data) >= 3:\n",
    "    ddos_sample = ddos_data.sample(3, random_state=42)\n",
    "    balanced_colab_samples.extend(ddos_sample.to_dict('records'))\n",
    "    print(f\"   ‚úÖ DDoS: 3 muestras seleccionadas\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Solo {len(ddos_data)} DDoS disponibles\")\n",
    "    balanced_colab_samples.extend(ddos_data.to_dict('records'))\n",
    "\n",
    "# 2. PortScan - 2 muestras\n",
    "portscan_data = test_meta[test_meta['original_label'] == 'PortScan']\n",
    "if len(portscan_data) >= 2:\n",
    "    portscan_sample = portscan_data.sample(2, random_state=42)\n",
    "    balanced_colab_samples.extend(portscan_sample.to_dict('records'))\n",
    "    print(f\"   ‚úÖ PortScan: 2 muestras seleccionadas\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Solo {len(portscan_data)} PortScan disponibles\")\n",
    "    balanced_colab_samples.extend(portscan_data.to_dict('records'))\n",
    "\n",
    "# 3. BENIGN - 5 muestras (3 normales + 2 inusuales)\n",
    "benign_data = test_meta[test_meta['original_label'] == 'BENIGN']\n",
    "\n",
    "# Para simular \"normales\" vs \"inusuales\" sin tener el label, usar distribuci√≥n aleatoria\n",
    "benign_sample = benign_data.sample(5, random_state=42)\n",
    "balanced_colab_samples.extend(benign_sample.to_dict('records'))\n",
    "print(f\"   ‚úÖ BENIGN: 5 muestras seleccionadas\")\n",
    "\n",
    "print(f\"üìä Total muestras balanceadas: {len(balanced_colab_samples)}\")\n",
    "\n",
    "# Verificar distribuci√≥n final\n",
    "final_types = [s['original_label'] for s in balanced_colab_samples]\n",
    "final_distribution = Counter(final_types)\n",
    "print(f\"üìã Distribuci√≥n final: {dict(final_distribution)}\")\n",
    "\n",
    "# === CREAR GROUND TRUTH PARA VALIDACI√ìN ===\n",
    "validation_ground_truth = []\n",
    "for sample in balanced_colab_samples:\n",
    "    if sample['original_label'] in ['DDoS', 'PortScan']:\n",
    "        validation_ground_truth.append('CONFIRMED')\n",
    "    else:\n",
    "        validation_ground_truth.append('DISCARDED')\n",
    "\n",
    "validation_balance = Counter(validation_ground_truth)\n",
    "print(f\"üéØ Balance de validaci√≥n: {dict(validation_balance)}\")\n",
    "\n",
    "# === PREPARAR PROMPTS DE VALIDACI√ìN CON CONTEXTO T√âCNICO ===\n",
    "print(f\"\\nüìù PREPARANDO PROMPTS DE VALIDACI√ìN:\")\n",
    "\n",
    "system_prompt = \"\"\"You are a senior cybersecurity analyst acting as a VALIDATION SPECIALIST.\n",
    "\n",
    "An automated anomaly detection system (TranAD+) has flagged network flows as potentially suspicious. Your role is to VALIDATE these detections.\n",
    "\n",
    "TASK: For each detection, determine if it should be CONFIRMED as a real threat or DISCARDED as a false positive.\n",
    "\n",
    "Respond in JSON format:\n",
    "{\n",
    "  \"validation\": \"CONFIRMED\" or \"DISCARDED\",\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"technical_justification\": \"detailed technical analysis\",\n",
    "  \"key_indicators\": [\"indicator1\", \"indicator2\"],\n",
    "  \"recommended_action\": \"specific action for security team\"\n",
    "}\"\"\"\n",
    "\n",
    "colab_validation_prompts = []\n",
    "\n",
    "for idx, sample in enumerate(balanced_colab_samples):\n",
    "\n",
    "    # Simular score TranAD+ realista\n",
    "    if sample['original_label'] in ['DDoS', 'PortScan']:\n",
    "        # Amenazas reales - scores altos\n",
    "        tranad_score = np.random.uniform(0.6, 0.95)\n",
    "        confidence_level = tranad_score / 0.02\n",
    "        expected_validation = 'CONFIRMED'\n",
    "    else:\n",
    "        # BENIGN - scores variables (algunos altos FP, otros bajos normales)\n",
    "        tranad_score = np.random.uniform(0.1, 0.8)\n",
    "        confidence_level = tranad_score / 0.02\n",
    "        expected_validation = 'DISCARDED'\n",
    "\n",
    "    # Contexto temporal\n",
    "    try:\n",
    "        ts_dt = pd.to_datetime(sample['timestamp_original'])\n",
    "        time_context = f\"{sample['timestamp_original']} ({ts_dt.strftime('%A')}, {'business hours' if 9 <= ts_dt.hour <= 17 else 'after hours'})\"\n",
    "    except:\n",
    "        time_context = f\"{sample.get('timestamp_original', 'Unknown time')}\"\n",
    "\n",
    "    # Determinar tipo de tr√°fico\n",
    "    source_ip = sample['_Source_IP_original']\n",
    "    dest_ip = sample['_Destination_IP_original']\n",
    "\n",
    "    if str(source_ip).startswith('192.168.') and str(dest_ip).startswith('192.168.'):\n",
    "        traffic_type = \"Internal LAN communication\"\n",
    "        risk_level = \"Baseline risk - internal network\"\n",
    "    elif str(source_ip).startswith('192.168.'):\n",
    "        traffic_type = \"Outbound LAN to Internet\"\n",
    "        risk_level = \"Medium risk - internal to external\"\n",
    "    elif str(dest_ip).startswith('192.168.'):\n",
    "        traffic_type = \"Inbound Internet to LAN\"\n",
    "        risk_level = \"High potential risk - external to internal\"\n",
    "    else:\n",
    "        traffic_type = \"External communication\"\n",
    "        risk_level = \"Unknown risk context\"\n",
    "\n",
    "    user_prompt = f\"\"\"NETWORK ANOMALY VALIDATION\n",
    "\n",
    "=== AUTOMATED DETECTION ALERT ===\n",
    "Detection System: TranAD+ Transformer Anomaly Detector\n",
    "Detection Timestamp: {time_context}\n",
    "Anomaly Score: {tranad_score:.4f}\n",
    "System Confidence: {confidence_level:.1f}x baseline threshold\n",
    "Alert Status: PENDING VALIDATION\n",
    "\n",
    "=== NETWORK FLOW ANALYSIS ===\n",
    "\n",
    "CONNECTION DETAILS:\n",
    "‚Ä¢ Source IP: {source_ip}\n",
    "‚Ä¢ Destination IP: {dest_ip}\n",
    "‚Ä¢ Flow ID: {sample['Flow_ID_original']}\n",
    "‚Ä¢ Traffic Classification: {traffic_type}\n",
    "‚Ä¢ Risk Assessment: {risk_level}\n",
    "\n",
    "CAPTURE CONTEXT:\n",
    "‚Ä¢ Data Source: {sample['source_file']}\n",
    "‚Ä¢ Collection Period: Network traffic monitoring dataset\n",
    "‚Ä¢ Flow Classification: Network security analysis\n",
    "\n",
    "=== VALIDATION REQUEST ===\n",
    "\n",
    "TranAD+ has flagged this network flow as ANOMALOUS with score {tranad_score:.4f}.\n",
    "\n",
    "As a security validation specialist, analyze this detection:\n",
    "\n",
    "1. Consider the network flow characteristics\n",
    "2. Evaluate the traffic direction and IP context\n",
    "3. Assess the anomaly score and system confidence\n",
    "4. Determine if this requires security team attention\n",
    "\n",
    "DECISION REQUIRED: Do you CONFIRM this as a valid security concern requiring escalation, or DISCARD it as a false positive?\n",
    "\n",
    "Provide technical justification for your validation decision.\"\"\"\n",
    "\n",
    "    colab_validation_prompts.append({\n",
    "        'validation_id': f\"COLAB_VAL_{idx:03d}\",\n",
    "        'system_prompt': system_prompt,\n",
    "        'user_prompt': user_prompt,\n",
    "        'expected_validation': expected_validation,\n",
    "        'original_label': sample['original_label'],\n",
    "        'tranad_score_simulated': tranad_score,\n",
    "        'network_context': {\n",
    "            'source_ip': source_ip,\n",
    "            'dest_ip': dest_ip,\n",
    "            'traffic_type': traffic_type,\n",
    "            'timestamp': sample['timestamp_original']\n",
    "        },\n",
    "        'sample_metadata': sample\n",
    "    })\n",
    "\n",
    "print(f\"‚úÖ {len(colab_validation_prompts)} prompts de validaci√≥n creados\")\n",
    "\n",
    "# Verificar balance final\n",
    "final_validation_balance = Counter([p['expected_validation'] for p in colab_validation_prompts])\n",
    "original_label_balance = Counter([p['original_label'] for p in colab_validation_prompts])\n",
    "\n",
    "print(f\"üìä Balance final de validaci√≥n: {dict(final_validation_balance)}\")\n",
    "print(f\"üìã Balance por tipo original: {dict(original_label_balance)}\")\n",
    "\n",
    "# === GUARDAR DATASET BALANCEADO CORRECTO ===\n",
    "corrected_dataset_path = f\"{BASELINE_PATH}/colab_validation_dataset_balanced_corrected.json\"\n",
    "with open(corrected_dataset_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(colab_validation_prompts, f, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "print(f\"üíæ Dataset balanceado correcto: {corrected_dataset_path}\")\n",
    "\n",
    "# === CHECKPOINT DE PREPARACI√ìN CORRECTA ===\n",
    "corrected_checkpoint = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'stage': 'C3_balanced_dataset_corrected',\n",
    "    'correct_distribution': dict(original_label_balance),\n",
    "    'validation_balance': dict(final_validation_balance),\n",
    "    'total_samples': len(colab_validation_prompts),\n",
    "    'matches_local_distribution': True,\n",
    "    'ready_for_model_evaluation': True\n",
    "}\n",
    "\n",
    "corrected_checkpoint_path = f\"{CHECKPOINT_PATH}/C3_corrected_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(corrected_checkpoint_path, 'w') as f:\n",
    "    json.dump(corrected_checkpoint, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Checkpoint: {corrected_checkpoint_path}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ DATASET BALANCEADO CORRECTO CREADO\")\n",
    "print(f\"‚úÖ DDoS: {original_label_balance.get('DDoS', 0)} muestras\")\n",
    "print(f\"‚úÖ PortScan: {original_label_balance.get('PortScan', 0)} muestras\")\n",
    "print(f\"‚úÖ BENIGN: {original_label_balance.get('BENIGN', 0)} muestras\")\n",
    "print(f\"‚úÖ Balance validaci√≥n: CONFIRMED={final_validation_balance.get('CONFIRMED', 0)}, DISCARDED={final_validation_balance.get('DISCARDED', 0)}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"[C3_CORRECTED_DATASET_READY] ‚úÖ\")\n",
    "print(\"üöÄ Dataset id√©ntico al local - listo para evaluaci√≥n de modelos full precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwzquEvinixf"
   },
   "source": [
    "## LLAMA-3-8B: ENTRENAMIENTO DIRECTO 10 000 (A100, REPRODUCIBLE, CELDA INDEPENDIENTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importaci√≥n de dependencias y configuraci√≥n inicial.**\n",
    "\n",
    "Se instalan y cargan las librer√≠as necesarias para el ajuste fino de modelos LLM (LLaMA‚ÄØ3, Qwen‚ÄØ2 y Foundation‚ÄëSec‚ÄØ8B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "38cc43a0436d4143958c8f0fc2576760",
      "7fce94a54b814c95a25a00907975113e",
      "1bc0a651c11f42f69400f6117c1d91e1",
      "d380009560c24db0a68409b4ead6a11b",
      "a553f10a812f48fb93deee4115948fcd",
      "9a6caf8ae3884c4a93421b6455f9ebce",
      "4674dcee216e45fdb95e68a2cb90e6a7",
      "b5983a76eea1485986eed428e384c391",
      "ca50d974d4d24972b6ea78572a5efd61",
      "8aec5a3863c54380a34bd12d2fc1b69d",
      "eb0e8350ba4c4a23a4e199e06c1af776",
      "73448f654cd54590a5871f8c62f2d000",
      "96eb6c064d46426884208f500a43c7f5",
      "154da19df66a42a180ba1050c1777fa3",
      "397ea417c5d644d6b7ec2309e4737f33",
      "d7759f9725f44e9bace8bbc6b973cc44",
      "ae05f2b01171433fadb4960ef689ad07",
      "9942c782a1774126a3f665fd44b0ae7d",
      "83d62c0cef94464391ae6f51efca7516",
      "839b3ebe4525413f8558f58cb88f1735",
      "e04a2ea6df7148348be4bf7d8da76ac2",
      "374426d1d7ad4a6588283083bff0e960",
      "0fe3c3ac4698436582fc9767fefa6da5",
      "943dfb5f7d734647b746dbb6856e73bd",
      "d2c59f3d5a8c4c4493c7541456b38071",
      "1cf3ddf7dcd344adb528d3246888015b",
      "aab9c34fcf404d34b4c5550500fe457c",
      "3f6155d0842a43a5a324ec6731036544",
      "b8265cefe7cd4e6fab0c6a032d0c75be",
      "0dcccf668d7e471ca6bff64551be3bf9",
      "2015ce5c00564736b3182b3abd05d635",
      "b6c48f0aca2445fe990f925503db3f25",
      "804cffba58f341319f73732dbc7b4e0a",
      "8e09800da6f842e3b4a3c0808dd97bae",
      "8dc1dfdf07b14d5dab7ec5c16d48e724",
      "7ba2f08d191f42e99e0e9362ad883827",
      "3bb94ba875af449f95aa043d4f2b1653",
      "76b798a7ef654de8b4de514a42e33d42",
      "d472354306364c2f8a223dbbee9caaf8",
      "a2da1b6b45dd4e31932395aff3e00d0c",
      "a452b426be2c4b6fa62f1c46c65dbab1",
      "14cc99d558e144ffb0e0b7c1b218dfed",
      "4e363d19b06045d6bd102b9356486a0c",
      "fcb331b4205d4fb091019e05ca8cc503",
      "79760f6202e345f6abb0dff52eef7d94",
      "87db21b967584f5d8de14bd9b5efa6a7",
      "4fa6f13687074d8b8e5e349537a75a5b",
      "ca067207c25c48229c1664960f9b8aab",
      "2dbdff4b586d4e60b44217c2a81b6bfd",
      "46fa4e37e9bd4fdd8df022cefce45562",
      "34431f4b621d4f5999efb963058f05aa",
      "93c5adc4b0254bbc89eb6bd7c781f25e",
      "1f417c50429e49f6b0abc051eee95517",
      "a0c64ce79d4f4d98afd512bb5dd6d903",
      "bb50b3a2490348059dc2b105b7551d98",
      "e76b4983dcf346d6940b90b67234dfd6",
      "80325cc34a1a48cdaec786aaef114790",
      "e6a802e689454e828274525e1ec027d8",
      "1feae66c409c4fa2a8330823eb22e6bd",
      "fda3b809306d44308e35b98a26395ef9",
      "0a4e70dab0364922a21a8bdaff72b806",
      "3b9e9cf2ed044e4192cf1a99226bedc2",
      "020ba9e10487410a8cfd441ab64e91d5",
      "b399d43f0e4649eab4b27108437911ad",
      "7775af7f317b474796ac9bb29dc8f088",
      "8cb6c5ab85374be69066cecb31d64a3f",
      "146d7b5bfd134bca9a28d993a6a70e84",
      "ff8bcdd7da3944538ad7a9e559749d7c",
      "5db0d6c1d41c4d1c89bfcaca80bc3778",
      "566142ec23da441280d9a0b7de47460f",
      "12a90969ea6b403a97d4dfe98f0ad904",
      "c594011662134dcfaf4e30fab3ad7de9",
      "ec4e430cf31944e6aecd59ad5e5a7283",
      "43abd0ff241c41488a6d8db145a609fd",
      "8317bdbce80c4dc1804fb5dcfcd536de",
      "0898b3a2db25421ab999ffd1894f79c2",
      "11712fd7891b49a291b0bb980e12c133",
      "4f1371adc10a476aa5479d8f73687d56",
      "9019a8f2c7e2428bb18d5e3a6358d1e7",
      "e9c72c78a09b41fe9fdf48f10fed3776",
      "11dc634178f1425794294103f9011f80",
      "5d72d78b14094e0c9c7c4c1d6803c314",
      "153a2b4caa1542c3a4bbe45a49b6dda6",
      "96024d0dd9de4779b04d1e886f61d6ee",
      "f0ee61b4953f47e48782f2ce92452be9",
      "73d2accb1a0946d780b68564c0bc9ed6",
      "838e9d61893741e6bf89b0924c50bf3c",
      "ef1fa27247cd46c094c8942717bdff7d",
      "15c9be91512f423ead3ccea95709207e",
      "5b362bfa2b09475c8a11e5372a0069a6",
      "0f9986c653b04a0592aca46ac35f2d90",
      "515381639a4a4141ae21fe162d90d2a3",
      "ab13cb6b968d45e1bd04576abf07f930",
      "6622368e33ca448f9c9839c7fa4ba636",
      "a6c7cd66db2042bab7a4aad15c69a214",
      "2e998275fb3541d8a8083f171a83a560",
      "1b1993af6304406aae16fe84b3f0be60",
      "583d8b70f2244acc8b82d11488f6a953",
      "15a66c0739ef44898ac6d195271c4815",
      "0e8afc3dafbc4999a24c0637271f597b",
      "888b3229f0c44028ae196e831f4a18ba",
      "dc19950617aa4fc7b76d5bd03198dc96",
      "605c9cd410824463bd3293be2e036afa",
      "c80ee8ea47164a3fb763c8618a27334b",
      "4deed82428094bbf89e17c41f2f4d2d3",
      "84667fa67e69451686d3559b66153ff2",
      "12749384bd7843e1b990f0467aba84a3",
      "050041cbc41a41dca4ef556ffb94615f",
      "45aa3c096bc448d09150be3d81aab3e6",
      "2eca9cd7d95c489ebe1ee11dafb3747a",
      "d15a204fceb2498c81892d62e98c21b5",
      "5b213cf5daaf4332ade2a92c5edb3d3f",
      "14860157c7cf419c9e9334e871278eb8",
      "292e76bd31334679bfb1eaeb8d5ee6e6",
      "768bb82456a5489c809678455e8a7f6c",
      "77128514622f4a538a6b7ec9804dab8d",
      "d3ea23abb496416b91de79c4fe52b674",
      "65ae5ae486c541f1ad8389b6d46800f5",
      "dc4edda21629487fa88e94a968a96473",
      "70544bf576b84170b95fd9607563a756",
      "98a427f58d924a68a74782108e87f53a",
      "d3646b03acd442d7b3f7b422882ca97d",
      "3ca96d321b354260a9f07218d19c2f53",
      "cbc05c7b3ca049079865479f65ffcf82",
      "c2337629261b4cc8839f5db6cd265e66",
      "eb68b05bc05e46ad85083a8e8ad1d97f",
      "1a4f89d62d2e470b8377d2236f68db9f",
      "d0705b700b394864ab441edca2502978",
      "c340048bab264907936f6b506201cf69",
      "9c72bcd5b5104e378c5a68dbf380f509",
      "51ccf88cb6714d809f39cfc3be99a318",
      "b6e3e9f00c8d452c817ae9977de9efc0",
      "fc3436c6e203495b99b4e3f5985831d5",
      "46f8a12ce0244a989094451b867697a2",
      "1cf7b80d77234b909a67d4daa328a1f3",
      "5b13681f0a694846871288b6e2da506f",
      "cd6acce337dc4a42ba2eb10b322502dd",
      "64e8d887514e44ccae53cc3aef0c7f58",
      "8f9e521d1cdb402aa4e05e1c86539e1f",
      "3c143215a3154d5196a1800c7a3299cf",
      "89b17d29618a4509b783d37f8649aaed",
      "3a567afb9bf44fa9979a923009dc450a",
      "35d895aa168d47578a57870930a836ec",
      "3931a8a2ca4849a48318e6ebb4e97d12",
      "5096e931a9f44874b3ca2604883426d9",
      "3478fff93ad2464e87d48f29e211e08e",
      "cd560c6641cc4f898cc55b68362e45b8",
      "1ffd76feeb8b45aeb980c65698ed939f",
      "db0b9ba2019d41b3993bf2f0efbea94b",
      "5bd5e6b9d39b4591a062bf8b09b6f2c3",
      "ef45b764edca417dbc8b6b20e786d8d7",
      "35823704aec942dc87b269e13e9f4679",
      "992adc70d21a4c4ba19ac38f7ddd566b",
      "b1af772fa746444ca3c6b3cf7673a383",
      "dfd0918986fc4def8b1862c01af1516d",
      "87f07cfab3fd4aefa95cc03d0d3c128a",
      "27fb0729f8ec452994427858f6c1aca7",
      "1699eccfe0f14c4196611944106aaf91",
      "1f2aa59ea6d14ded92ec1c7f9d64baa1",
      "f98951f9662f4f568475b88d60889242",
      "a1b587b2d76843358c0a1ae327827cac",
      "5dfeccfb900545b38b38330629c664cc",
      "7958a578db294e068a273c9ac4f86360",
      "b6c86d0d91f64fdebd7f7ac97bf1dfa9",
      "4ea3c1d9470143df9a9a1a1725edb4ab",
      "a1f97f3e27f64104bb8db494c60c6aa1",
      "484da3df849e44bf8ed954ee4cd7aa4e",
      "3be63671001b40b5a927b0b80ceb647a",
      "8f16953fe71247d7ab2bef08e958595d",
      "8e39ac9d1b294a7faa4cfda38b7ab351",
      "7eae449dd64c402cb7e30aa919396393",
      "1dadfbdac1c747fab1fc4e43e308dd0d",
      "7a66aaad70f64e1193941641d5ddb108",
      "c32443a5cf834a40ba4c635fcf2063bb",
      "5265cfd57ba44805bf6acd33f64e731b",
      "18aebbce530b4c4583b55add8b404902"
     ]
    },
    "executionInfo": {
     "elapsed": 1879085,
     "status": "ok",
     "timestamp": 1760997162236,
     "user": {
      "displayName": "Javier Moreno",
      "userId": "15898376622721324964"
     },
     "user_tz": 300
    },
    "id": "5Z9KrXIOnjpC",
    "outputId": "49bf2b75-1ffa-4bd6-d524-25fa14766403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hü¶ô LLaMA-3-8B ‚Äî Entrenamiento 10k (A100, BF16, 4-bit, reproducible)\n",
      "============================================================================================\n",
      "‚ÑπÔ∏è Nota TFM: Se utiliza un subconjunto REPRESENTATIVO de 10 000 ejemplos para comparaci√≥n\n",
      "             justa y reproducible entre modelos (misma muestra, misma semilla).\n",
      "üíæ GPU inicial: 0.0/85.2 GB\n",
      "\n",
      "üì¶ Cargando dataset...\n",
      "‚úÖ Dataset cargado: 10,000 ejemplos (fijos, reproducibles)\n",
      "\n",
      "üì• Cargando modelo/tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cc43a0436d4143958c8f0fc2576760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73448f654cd54590a5871f8c62f2d000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe3c3ac4698436582fc9767fefa6da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e09800da6f842e3b4a3c0808dd97bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79760f6202e345f6abb0dff52eef7d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76b4983dcf346d6940b90b67234dfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146d7b5bfd134bca9a28d993a6a70e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1371adc10a476aa5479d8f73687d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c9be91512f423ead3ccea95709207e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8afc3dafbc4999a24c0637271f597b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15a204fceb2498c81892d62e98c21b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3646b03acd442d7b3f7b422882ca97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 524,288 || all params: 8,030,785,536 || trainable%: 0.0065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3436c6e203495b99b4e3f5985831d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3931a8a2ca4849a48318e6ebb4e97d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd0918986fc4def8b1862c01af1516d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f97f3e27f64104bb8db494c60c6aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Entrenando LLaMA-3-8B con 10 000 ejemplos (A100, reproducible)...\n",
      "üïê Inicio: 21:24:01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 28:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.532200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.588500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.902200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.338600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.245500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.232400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.220500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.204800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.200400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.200100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.194600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.200300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.194200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.188900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.196500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.185300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.185400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.187900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.183100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.186300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.186600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ ENTRENAMIENTO COMPLETADO\n",
      "   ‚è±Ô∏è Duraci√≥n: 28.6 min\n",
      "   üìâ Loss final: 0.333\n",
      "   ü™ú Steps: 2500\n",
      "\n",
      "üíæ Modelo guardado en: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/03_fine_tuning/llama_direct_10k/weights/llama_direct_10k_20251020_215240\n",
      "üßæ Resumen: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/03_fine_tuning/llama_direct_10k/llama_direct_10k_summary_20251020_215240.json\n",
      "\n",
      "üßπ Memoria liberada. Celda independiente completada.\n"
     ]
    }
   ],
   "source": [
    "# === LLAMA-3-8B: ENTRENAMIENTO DIRECTO 10 000 (A100, REPRODUCIBLE, CELDA INDEPENDIENTE) ===\n",
    "\"\"\"\n",
    "- Modelo: meta-llama/Meta-Llama-3-8B-Instruct\n",
    "- T√©cnica: LoRA + 4-bit (NF4) con bitsandbytes\n",
    "- Dispositivo: A100 (BF16)\n",
    "- Reproducibilidad: semillas fijadas (random, numpy, torch, transformers.set_seed)\n",
    "- Esta celda es independiente: instala deps, carga datos, entrena, guarda y limpia memoria.\n",
    "- Nota (TFM): Se usa un subconjunto representativo de 10 000 ejemplos para comparaci√≥n justa entre LLMs.\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------\n",
    "# Instalaci√≥n r√°pida (celda independiente)\n",
    "# ----------------------------\n",
    "!pip install -q transformers peft trl datasets accelerate bitsandbytes\n",
    "\n",
    "# ----------------------------\n",
    "# Imports\n",
    "# ----------------------------\n",
    "import os, json, random, gc, numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from trl import SFTTrainer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibilidad (semillas fijas)\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "set_seed(SEED)  # reproducibilidad en Trainer/SFTTrainer\n",
    "\n",
    "print(\"ü¶ô LLaMA-3-8B ‚Äî Entrenamiento 10k (A100, BF16, 4-bit, reproducible)\")\n",
    "print(\"=\" * 92)\n",
    "print(\"‚ÑπÔ∏è Nota TFM: Se utiliza un subconjunto REPRESENTATIVO de 10 000 ejemplos para comparaci√≥n\")\n",
    "print(\"             justa y reproducible entre modelos (misma muestra, misma semilla).\")\n",
    "\n",
    "# ----------------------------\n",
    "# Paths y configuraci√≥n\n",
    "# ----------------------------\n",
    "BASE_PATH = '/content/drive/MyDrive/TFM_CIC_Anomaly_Detection'\n",
    "OUT_PATH = f'{BASE_PATH}/03_fine_tuning/llama_direct_10k'\n",
    "os.makedirs(f'{OUT_PATH}/weights', exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "DATASET_FILE = f\"{BASE_PATH}/03_fine_tuning/dataset_preparation/validator_finetune_train_20251002_173852.jsonl\"\n",
    "DATASET_SIZE = 10_000  # fijo a 10k para comparabilidad\n",
    "\n",
    "# Hiperpar√°metros (A100 40GB; ajustables si hace falta)\n",
    "PER_DEVICE_BATCH = 2\n",
    "GRAD_ACC = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-5\n",
    "LOG_STEPS = 50\n",
    "SAVE_STEPS = 1000\n",
    "\n",
    "# ----------------------------\n",
    "# Verificaci√≥n de memoria (opcional)\n",
    "# ----------------------------\n",
    "if torch.cuda.is_available():\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "    print(f\"üíæ GPU inicial: {allocated:.1f}/{total_mem:.1f} GB\")\n",
    "\n",
    "# ----------------------------\n",
    "# Cargar dataset (primeros 10 000) y formatear prompt LLaMA\n",
    "# ----------------------------\n",
    "print(\"\\nüì¶ Cargando dataset...\")\n",
    "with open(DATASET_FILE, 'r') as f:\n",
    "    full_data = [json.loads(line) for line in f]\n",
    "\n",
    "train_data = full_data[:DATASET_SIZE]\n",
    "print(f\"‚úÖ Dataset cargado: {len(train_data):,} ejemplos (fijos, reproducibles)\")\n",
    "\n",
    "def llama_format(example):\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{example['system']}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{example['user']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{example['assistant']}<|eot_id|>\"\"\"\n",
    "\n",
    "formatted_texts = [llama_format(ex) for ex in train_data]\n",
    "train_dataset = Dataset.from_dict({\"text\": formatted_texts})\n",
    "\n",
    "# ----------------------------\n",
    "# Cargar modelo/tokenizer (A100-friendly: BF16 + 4-bit NF4)\n",
    "# ----------------------------\n",
    "print(\"\\nüì• Cargando modelo/tokenizer...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # A100 ‚áí BF16\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,             # A100 ‚áí BF16\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    "    # Si tu build soporta Flash Attention 2:\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ----------------------------\n",
    "# LoRA m√≠nima (id√©ntica entre LLMs)\n",
    "# ----------------------------\n",
    "lora_cfg = LoraConfig(\n",
    "    r=2,\n",
    "    lora_alpha=4,\n",
    "    target_modules=[\"q_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_cfg)\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "# (Opcional) m√°s memoria de activaciones si subes batch/seq:\n",
    "# peft_model.gradient_checkpointing_enable()\n",
    "\n",
    "# ----------------------------\n",
    "# TrainingArguments\n",
    "# ----------------------------\n",
    "args = TrainingArguments(\n",
    "    output_dir=f'{OUT_PATH}/checkpoints',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=PER_DEVICE_BATCH,\n",
    "    gradient_accumulation_steps=GRAD_ACC,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_steps=LOG_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    fp16=False,            # A100 ‚áí usar BF16\n",
    "    bf16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# SFTTrainer\n",
    "# ----------------------------\n",
    "trainer = SFTTrainer(\n",
    "    model=peft_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    formatting_func=lambda x: x[\"text\"]\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Entrenamiento\n",
    "# ----------------------------\n",
    "print(\"\\nüöÄ Entrenando LLaMA-3-8B con 10 000 ejemplos (A100, reproducible)...\")\n",
    "start = datetime.now()\n",
    "print(f\"üïê Inicio: {start.strftime('%H:%M:%S')}\")\n",
    "\n",
    "result = trainer.train()\n",
    "\n",
    "end = datetime.now()\n",
    "dur_min = (end - start).total_seconds() / 60\n",
    "print(\"\\nüéâ ENTRENAMIENTO COMPLETADO\")\n",
    "print(f\"   ‚è±Ô∏è Duraci√≥n: {dur_min:.1f} min\")\n",
    "print(f\"   üìâ Loss final: {result.training_loss:.3f}\")\n",
    "print(f\"   ü™ú Steps: {result.global_step}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Guardado + resumen\n",
    "# ----------------------------\n",
    "timestamp = end.strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_path = f\"{OUT_PATH}/weights/llama_direct_10k_{timestamp}\"\n",
    "trainer.save_model(final_path)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\": end.isoformat(),\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"dataset_examples\": DATASET_SIZE,\n",
    "    \"final_loss\": float(result.training_loss),\n",
    "    \"duration_minutes\": float(dur_min),\n",
    "    \"per_device_batch\": PER_DEVICE_BATCH,\n",
    "    \"grad_acc\": GRAD_ACC,\n",
    "    \"precision\": \"bf16\",\n",
    "    \"seed\": SEED,\n",
    "    \"model_path\": final_path,\n",
    "    \"representative_subset_note\": \"Se usa subconjunto representativo de 10k para comparaci√≥n justa entre LLMs.\"\n",
    "}\n",
    "summary_path = f\"{OUT_PATH}/llama_direct_10k_summary_{timestamp}.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Modelo guardado en: {final_path}\")\n",
    "print(f\"üßæ Resumen: {summary_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Limpieza de memoria (para poder reiniciar/continuar otras celdas)\n",
    "# ----------------------------\n",
    "del trainer, peft_model, model, tokenizer, train_dataset, formatted_texts, train_data, full_data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nüßπ Memoria liberada. Celda independiente completada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_n9FtCBhJu-"
   },
   "source": [
    "## QWEN: ENTRENAMIENTO DIRECTO 10 000 (A100, REPRODUCIBLE, CELDA INDEPENDIENTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importaci√≥n de dependencias y configuraci√≥n inicial.**\n",
    "\n",
    "Se instalan y cargan las librer√≠as necesarias para el ajuste fino de modelos LLM (LLaMA‚ÄØ3, Qwen‚ÄØ2 y Foundation‚ÄëSec‚ÄØ8B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9202fb2e917745fbaceaf6e42cc4cc1e",
      "9ee3c2badd36442a908cd506b8e0f9ca",
      "185f94e138c240ea9d2d7c310b451982",
      "6ba546f711414107aebb3e085015cf0b",
      "b5bd9810d28840479c8163d5f4ed51e0",
      "9bc6c44620fd4d0fab72f0eb8561366f",
      "00d5c8a425c94f3e85edee211a31ccc0",
      "649b8b4ee26d4aa89c709ff99839bc6c",
      "8662038f45e74585922dbd6a03b5f1e1",
      "56d50f00b408437e82fd8112934c87a9",
      "3ffd88442e5d4821a0f26f604a761582",
      "1bf3b2ed870e487eafdcc670a7252bb6",
      "35d141ec0cb241d4b5b4f609d907c7be",
      "f9d79351565d499f9b990f6b23d78fdb",
      "297f7797937245fc9c777c53f78fa9e9",
      "b33ea9c5a28443f69e014d34eb66483a",
      "57846040a4a04113b2c7d7f6df303750",
      "7339ffd713434a51a38578dd635d553e",
      "9ca39fb108f74d349dd752752470cc38",
      "7b13398500f04db4b44c6cd0a4944ecf",
      "131a8ac7bd1e4b3d999d44373c69946f",
      "fc6e752265324e82a8291d5975bc1277",
      "c8571f64277f41ba9c0a0c915a774687",
      "c8a7b6aa74754602a59578e9e8c33772",
      "465a06e69093468a872889311f333d8a",
      "b475347b48ae4e6e9d05c3e9749ce31a",
      "0e2a5b318e8449f689296713cc34d274",
      "e0b8429a3cc841afaf4337026ea31da4",
      "f77f10e01c3d414ca9e3d98eee57f76f",
      "ccc2a91ea2314548a10775f7ec326b8b",
      "0be3f60085674266a6ad9f5afffa3073",
      "f131b6813295400a98fb4504535f18cc",
      "8dd5c8644c464e03b5386fef00a67f3a",
      "2665c092b0da43edbcc5a92e4f8a809b",
      "652fac7686304c1daafe72ce49264dba",
      "08d24a72ae5845e18f2f2cadbd4bf210",
      "75ae4cfc9907461a8d7766e253f01726",
      "7efbcec2ed5c421aa208452ccd2c84bd",
      "240f0af7f19444e09dcdb98c87fcb4af",
      "c0e926cf06d540d3adc52384dfb1ff79",
      "2bc0933f723f48fca1e3cc740a89a605",
      "411d785d688f40f08d1fd63e87afb47a",
      "18a30363a74c42d1ac9142a187c3c2e2",
      "1e6304690162491c9810399987bc43f3",
      "efaf5946dbf64b37aaa8ce6e0f2ebe27",
      "95f401d80fb348c699bed7cf7f2c45dc",
      "ab20bd8e8c7f421997b76b82b70b1dc4",
      "76e785cdb3ad45f7a502518735cadfd6",
      "62ea8af4502e41228fcdb9958f1977df",
      "eb603992176746a381dcb8559d60b13d",
      "2bc192242e074a3facd1917018c6d075",
      "73716f9918e84bb8a54acbfb64e641d3",
      "aaf79a30b867492f9ffaf5ad8d21185c",
      "17721fef23e148a6a3471c2db1d11ad7",
      "0f4582d4000f41bcbb8938e28ad17f23",
      "27f457d3d42e4195b2ff237f68ba0d84",
      "663db24882464ef58f35fa0d397cd095",
      "bcf395c9880c4a0b9890e67599d4bff0",
      "4fa834ee709941e98c8cb01b47caaa1d",
      "14518814aca14f21a82a3b05fdd2a322",
      "449f58147d2f490c87ed81eed4196131",
      "4288fc2de8404654a5c611008d782dad",
      "ec651352cd4544348483b3021d47c037",
      "c978fb64a4124dddad6df7f6568c95bf",
      "d69f44ef324b4852ac433912c9a7b690",
      "52970c5f370b455ab929061fd6f5555a",
      "aae812ee33e0436192d6516ee67da331",
      "1604d58857014122a3b0abeeff54ff08",
      "6d02111fa6b84ea6b21ebb51081ba6ea",
      "e3b186792ad543e38e04e2a1016cfaef",
      "204cfd6a2d6b465c9e94c97e62501cd1",
      "1524e6a698194c70b2d0a11c563da91a",
      "2d2ccfa6a98c459697fbfca7a45f7de9",
      "588981029e8748ca8c5215dfe45535ee",
      "c80f0aca108949a4bb9962c07aa1e8bb",
      "65bf19babfec43d6b4f95bc06234f2cc",
      "5aa1e68616dd41ccaf0957f982b6c11e",
      "5fb0e717021b44c4b1c82ca829cbde1d",
      "ecfb05e110d44757b84dda744eb511ad",
      "3381a3ebfe7446248ee3f090be42ded1",
      "24a0c70c933046ce8c1399cb5874bb44",
      "b9486caf21674fc3b2479e612cc48074",
      "d1aec96c226c44f08a9d3bdb47cd3de8",
      "0c7f7e5203e747388060e67ce4623978",
      "1ca113519c1446c7b7943b2872765791",
      "3a7e6aa505f44d99b2243c4b74d58887",
      "2ea98343eb954fcdbd8e7be76b761d38",
      "167b865a98bb4810a2cfb0c75ea32b75",
      "0f0748b7d73644048466c831503679bb",
      "fa0cbabf83db40c49b7c875a75b98b9c",
      "c6fc156ca6454304a69120cae38c0943",
      "72b8821288374aac87d70e4f73ab4b0b",
      "93fe2c769fb9404686521a6e8f445a36",
      "238e459cbb5e40779d63349e9afd7da3",
      "59c66ae1b3a0494cabbe365248990640",
      "dec979284bf3475db316f5fba11e9946",
      "5ad6fe333c2d4f5eb19f365bb4b954d6",
      "7993656219b546de988788c0bea07b07",
      "b57fc84fb9a24842aa3f43d02d372d89",
      "8900cae4adbc42f2a0098caa21c1cadf",
      "07a5704bf4d84c6bb7251f34facdc11f",
      "6ccabd35d7fe4fddb8c86e06f7b84942",
      "df2549159441403b99fe8c514a2e41d0",
      "b15dfe00c93d46438210cdaa68dd6fd6",
      "5b9f3efedf874f58a7c73f97ffc302ec",
      "7acba7c9ff074aa7ba4f9306508eb82e",
      "dc2b2a19939d46e9870c7974e55c928c",
      "0db49d4c0a6442b79dc92fb9f0fcc6f2",
      "83fe6e961de1447ea645abe9d7fb103a",
      "854f4681197948389de8bae8ed234b70",
      "97e95c49dca845c6a64714dafe1bc3c9",
      "96c94ea230d54e06821ff96346d64eaa",
      "6696687ed5b44d7aaec0093ace147e94",
      "15ed1ffcb588466194c6329e46f6f6d3",
      "d0971086ae3f49c4a7f4ce8177210fdd",
      "94b693a4d12740e5a447ba626146da2f",
      "6b7cd536a2594f48a269aa1b9e4810e6",
      "9447076d2deb4c8b926c48a0cff6e0c1",
      "630b68e383d04de797201678ac158c61",
      "a0b1bb268f644798afef75a987813b92",
      "0b9666d912164bcabb50ebde34e436f7",
      "324a5ffe2bcc4cfba2f4c9a3ea19ced6",
      "d6f1ae82791f4fc7b892471cb6276d52",
      "ea1e06a13b7a4db6af1387310fd44cb5",
      "fc5812a9bfb549ddb1f02edc6526248f",
      "18881f434d2b4b6ca5d7ed1ccfd500cf",
      "7a40faef5d384da78acede259f8f1124",
      "611e25619cd242d9adaf147d888f2fcb",
      "a83a7e36b6fb474ebc2ccc87b62a36d4",
      "bc5647591b6444d496c479140e1bdc15",
      "805667e6a33040db9f5da24ca4e71cfe",
      "c57afc2ac555463d8be50e90652b3090",
      "3710b3ea849149a5a964fac8e007cc85",
      "27fc774b49ef4bb184b1912791b12751",
      "489d0df5d3cc4c17b88e8b00562f9ad2",
      "715b3afd568d497693cb0ea5ff86879d",
      "c377522c4a7544e7bde0fd0ed9693f57",
      "f0a50c0b0ef24353bc636bfc5a140510",
      "01fdccf38f4f4e19b403443a05b85762",
      "e8cdb23de693481e9dfd1c93be73b063",
      "205d8a287a0143c49c1e0f5ac073c069",
      "32a89cba38704b17a7bc946261a4e638",
      "4383f814a9c54b43b963d9b30ab50740",
      "3cf78b739d7d4a29a7e880db1b1a5cdb",
      "4563e037e7974a0a9cb588c0c9086d67",
      "44225b40eaf7485f849648ae95924190",
      "85d5c421c41f4adfb1b3310b21a34e3a",
      "5ae3991bee254a9fb18b2a1f0792f8bb",
      "9a91211411904e25b84908c1f0037373",
      "8daa9d5f13f74d3d84bc209c9cd44b05",
      "cbc245bfc1ee48259a27246396db76b7",
      "08540338e4234dfbba689e9d7497014f",
      "e868f9e709ea44299aa0901c9750fad9",
      "ae95dee98205452785032eb4c7ddbde5",
      "6971213e83ba4920a1656377b6196b5d",
      "e0c194d8c8014d5bbbd823619a6a121f",
      "af5a8e6ba9bb4d65a30de9098fc8bf3d",
      "ac07bddf52ef47ce944b0f46934ca4d2",
      "7a9edf75bb5b4795b12ab5d3930ab2dc",
      "4491b57b99d648379d16c42e1424ee3e",
      "350dffb6acaa4e588db38dad404ed0cb",
      "caed422d0fd841ccbc16f2e157a0a64e",
      "11fa9c40049346f8935ab12d0f00f3a9",
      "90026da2be4b46abb6e9e4420ea7ce84",
      "1dbee2afeac74f8ab49db73a186149c6",
      "a7116248962d4325ab0fca98fa26664d",
      "4bcf655ad01e4810b27df6099c4919c0",
      "9dd2a8763d4248979c115f4d39a333e4",
      "ac9d6f7d03654c748457bf2bc1aeea74",
      "69e6ca8b494c4eb7bfed4c18e8c2f56c",
      "709293316a5648f6a6d3a03142c60741",
      "175c3d6dfea941a6b97b69ed7787876a",
      "f48431e5d2194b729a9bda448364e2b3",
      "b18f180109464778ada3863212af6b0e",
      "0795468ab5404198bea99d322c6246ee",
      "c46c4075e0ca41819a41a68dc2907f70",
      "a6b14b3a20fa49dfbcf1a2283b5e010c",
      "e8ab45c7e5e241079c9495514ba0b24d",
      "643b9cc19bf34a3ea21f8499d9f13ae9",
      "b57507561b9040769efdf6260c3a07bf",
      "dbc70e30506d4df88a8d73802ce62eb5",
      "ca0c38b0b99b49c186bcfaf012b7fe53",
      "92f653374c1945038bb380789132fea2",
      "02ae8898f84e4f03991deae5ee5e9343",
      "9f0f2d203f1547cbb922e2c9c28455b6",
      "75f3007e09bd441ca1564b65d16cdd34",
      "b2cf2608a33343188a6edb91baa725cb"
     ]
    },
    "executionInfo": {
     "elapsed": 1219954,
     "status": "ok",
     "timestamp": 1760999132103,
     "user": {
      "displayName": "Javier Moreno",
      "userId": "15898376622721324964"
     },
     "user_tz": 300
    },
    "id": "g187n8L7hSJw",
    "outputId": "8941fdbd-b071-44fe-8814-3c1f7be2d7ab"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Qwen1.5-7B ‚Äî Entrenamiento 10k (A100, BF16, 4-bit, reproducible)\n",
      "============================================================================================\n",
      "‚ÑπÔ∏è Nota TFM: Se utiliza un subconjunto REPRESENTATIVO de 10 000 ejemplos para comparaci√≥n\n",
      "             justa y reproducible entre modelos (misma muestra, misma semilla).\n",
      "üíæ GPU inicial: 0.0/85.2 GB\n",
      "\n",
      "üì¶ Cargando dataset...\n",
      "‚úÖ Dataset cargado: 10,000 ejemplos (fijos, reproducibles)\n",
      "\n",
      "üì• Cargando modelo/tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9202fb2e917745fbaceaf6e42cc4cc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf3b2ed870e487eafdcc670a7252bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8571f64277f41ba9c0a0c915a774687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2665c092b0da43edbcc5a92e4f8a809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efaf5946dbf64b37aaa8ce6e0f2ebe27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f457d3d42e4195b2ff237f68ba0d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae812ee33e0436192d6516ee67da331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb0e717021b44c4b1c82ca829cbde1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0748b7d73644048466c831503679bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8900cae4adbc42f2a0098caa21c1cadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e95c49dca845c6a64714dafe1bc3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324a5ffe2bcc4cfba2f4c9a3ea19ced6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3710b3ea849149a5a964fac8e007cc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 524,288 || all params: 7,721,848,832 || trainable%: 0.0068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf78b739d7d4a29a7e880db1b1a5cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6971213e83ba4920a1656377b6196b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7116248962d4325ab0fca98fa26664d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b14b3a20fa49dfbcf1a2283b5e010c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Entrenando Qwen1.5-7B con 10 000 ejemplos (A100, reproducible)...\n",
      "üïê Inicio: 21:55:20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='837' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 837/2500 09:49 < 19:34, 1.42 it/s, Epoch 0.33/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.874600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.249700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.215000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 30:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.874600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.249700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.205800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.193400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.187400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.184300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.179700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.179700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.177100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.172300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.171700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.171700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.170500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.171300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.167100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ ENTRENAMIENTO COMPLETADO\n",
      "   ‚è±Ô∏è Duraci√≥n: 30.2 min\n",
      "   üìâ Loss final: 0.407\n",
      "   ü™ú Steps: 2500\n",
      "\n",
      "üíæ Modelo guardado en: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/03_fine_tuning/qwen_direct_10k/weights/qwen_direct_10k_20251020_222530\n",
      "üßæ Resumen: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/03_fine_tuning/qwen_direct_10k/qwen_direct_10k_summary_20251020_222530.json\n",
      "\n",
      "üßπ Memoria liberada. Celda independiente completada.\n"
     ]
    }
   ],
   "source": [
    "# === QWEN-1.5-7B: ENTRENAMIENTO DIRECTO 10 000 (A100, REPRODUCIBLE, CELDA INDEPENDIENTE) ===\n",
    "\"\"\"\n",
    "- Modelo: Qwen/Qwen1.5-7B-Chat\n",
    "- T√©cnica: LoRA + 4-bit (NF4) con bitsandbytes\n",
    "- Dispositivo: A100 (BF16)\n",
    "- Reproducibilidad: semillas fijadas (random, numpy, torch, transformers.set_seed)\n",
    "- Celda independiente: instala deps, carga datos, entrena, guarda y limpia memoria.\n",
    "- Nota (TFM): Se usa un subconjunto REPRESENTATIVO de 10 000 ejemplos para comparaci√≥n justa entre LLMs.\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------\n",
    "# Instalaci√≥n r√°pida (celda independiente)\n",
    "# ----------------------------\n",
    "!pip install -q transformers peft trl datasets accelerate bitsandbytes\n",
    "\n",
    "# ----------------------------\n",
    "# Imports\n",
    "# ----------------------------\n",
    "import os, json, random, gc, numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from trl import SFTTrainer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibilidad (semillas fijas)\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "set_seed(SEED)  # reproducibilidad en Trainer/SFTTrainer\n",
    "\n",
    "print(\"üîÆ Qwen1.5-7B ‚Äî Entrenamiento 10k (A100, BF16, 4-bit, reproducible)\")\n",
    "print(\"=\" * 92)\n",
    "print(\"‚ÑπÔ∏è Nota TFM: Se utiliza un subconjunto REPRESENTATIVO de 10 000 ejemplos para comparaci√≥n\")\n",
    "print(\"             justa y reproducible entre modelos (misma muestra, misma semilla).\")\n",
    "\n",
    "# ----------------------------\n",
    "# Paths y configuraci√≥n\n",
    "# ----------------------------\n",
    "BASE_PATH = '/content/drive/MyDrive/TFM_CIC_Anomaly_Detection'\n",
    "OUT_PATH = f'{BASE_PATH}/03_fine_tuning/qwen_direct_10k'\n",
    "os.makedirs(f'{OUT_PATH}/weights', exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen1.5-7B-Chat\"\n",
    "DATASET_FILE = f\"{BASE_PATH}/03_fine_tuning/dataset_preparation/validator_finetune_train_20251002_173852.jsonl\"\n",
    "DATASET_SIZE = 10_000  # fijo a 10k para comparabilidad\n",
    "\n",
    "# Hiperpar√°metros (A100 40GB; ajustables si hace falta)\n",
    "PER_DEVICE_BATCH = 2\n",
    "GRAD_ACC = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-5\n",
    "LOG_STEPS = 50\n",
    "SAVE_STEPS = 1000\n",
    "\n",
    "# ----------------------------\n",
    "# Verificaci√≥n de memoria (opcional)\n",
    "# ----------------------------\n",
    "if torch.cuda.is_available():\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "    print(f\"üíæ GPU inicial: {allocated:.1f}/{total_mem:.1f} GB\")\n",
    "\n",
    "# ----------------------------\n",
    "# Cargar dataset (primeros 10 000) y formatear prompts Qwen\n",
    "# ----------------------------\n",
    "print(\"\\nüì¶ Cargando dataset...\")\n",
    "with open(DATASET_FILE, 'r') as f:\n",
    "    full_data = [json.loads(line) for line in f]\n",
    "\n",
    "train_data = full_data[:DATASET_SIZE]\n",
    "print(f\"‚úÖ Dataset cargado: {len(train_data):,} ejemplos (fijos, reproducibles)\")\n",
    "\n",
    "# Formato de chat para Qwen (id√©ntico a tu versi√≥n)\n",
    "def qwen_format(example):\n",
    "    return f\"\"\"<|im_start|>system\n",
    "{example['system']}<|im_end|>\n",
    "<|im_start|>user\n",
    "{example['user']}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{example['assistant']}<|im_end|>\"\"\"\n",
    "\n",
    "formatted_texts = [qwen_format(ex) for ex in train_data]\n",
    "train_dataset = Dataset.from_dict({\"text\": formatted_texts})\n",
    "\n",
    "# ----------------------------\n",
    "# Cargar modelo/tokenizer (A100-friendly: BF16 + 4-bit NF4)\n",
    "# ----------------------------\n",
    "print(\"\\nüì• Cargando modelo/tokenizer...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # A100 ‚áí BF16\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,             # A100 ‚áí BF16\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True\n",
    "    # Si tu build soporta Flash Attention 2:\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "qwen_tokenizer.pad_token = qwen_tokenizer.eos_token\n",
    "\n",
    "# ----------------------------\n",
    "# LoRA m√≠nima (id√©ntica entre LLMs)\n",
    "# ----------------------------\n",
    "lora_cfg = LoraConfig(\n",
    "    r=2,\n",
    "    lora_alpha=4,\n",
    "    target_modules=[\"q_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "qwen_peft = get_peft_model(qwen_model, lora_cfg)\n",
    "qwen_peft.print_trainable_parameters()\n",
    "\n",
    "# (Opcional) m√°s memoria de activaciones si subes batch/seq:\n",
    "# qwen_peft.gradient_checkpointing_enable()\n",
    "\n",
    "# ----------------------------\n",
    "# TrainingArguments\n",
    "# ----------------------------\n",
    "args = TrainingArguments(\n",
    "    output_dir=f'{OUT_PATH}/checkpoints',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=PER_DEVICE_BATCH,\n",
    "    gradient_accumulation_steps=GRAD_ACC,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_steps=LOG_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    fp16=False,            # A100 ‚áí usar BF16\n",
    "    bf16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# SFTTrainer\n",
    "# ----------------------------\n",
    "trainer = SFTTrainer(\n",
    "    model=qwen_peft,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=qwen_tokenizer,\n",
    "    formatting_func=lambda x: x[\"text\"]\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Entrenamiento\n",
    "# ----------------------------\n",
    "print(\"\\nüöÄ Entrenando Qwen1.5-7B con 10 000 ejemplos (A100, reproducible)...\")\n",
    "start = datetime.now()\n",
    "print(f\"üïê Inicio: {start.strftime('%H:%M:%S')}\")\n",
    "\n",
    "result = trainer.train()\n",
    "\n",
    "end = datetime.now()\n",
    "dur_min = (end - start).total_seconds() / 60\n",
    "print(\"\\nüéâ ENTRENAMIENTO COMPLETADO\")\n",
    "print(f\"   ‚è±Ô∏è Duraci√≥n: {dur_min:.1f} min\")\n",
    "print(f\"   üìâ Loss final: {result.training_loss:.3f}\")\n",
    "print(f\"   ü™ú Steps: {result.global_step}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Guardado + resumen\n",
    "# ----------------------------\n",
    "timestamp = end.strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_path = f\"{OUT_PATH}/weights/qwen_direct_10k_{timestamp}\"\n",
    "trainer.save_model(final_path)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\": end.isoformat(),\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"dataset_examples\": DATASET_SIZE,\n",
    "    \"final_loss\": float(result.training_loss),\n",
    "    \"duration_minutes\": float(dur_min),\n",
    "    \"per_device_batch\": PER_DEVICE_BATCH,\n",
    "    \"grad_acc\": GRAD_ACC,\n",
    "    \"precision\": \"bf16\",\n",
    "    \"seed\": SEED,\n",
    "    \"model_path\": final_path,\n",
    "    \"representative_subset_note\": \"Se usa subconjunto representativo de 10k para comparaci√≥n justa entre LLMs.\"\n",
    "}\n",
    "summary_path = f\"{OUT_PATH}/qwen_direct_10k_summary_{timestamp}.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Modelo guardado en: {final_path}\")\n",
    "print(f\"üßæ Resumen: {summary_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Limpieza de memoria (para poder reiniciar/continuar otras celdas)\n",
    "# ----------------------------\n",
    "del trainer, qwen_peft, qwen_model, qwen_tokenizer, train_dataset, formatted_texts, train_data, full_data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nüßπ Memoria liberada. Celda independiente completada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmHANagCiiM1"
   },
   "source": [
    "## FOUNDATION-SEC: ENTRENAMIENTO DIRECTO 10 000 (A100, REPRODUCIBLE, CELDA INDEPENDIENTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importaci√≥n de dependencias y configuraci√≥n inicial.**\n",
    "\n",
    "Se instalan y cargan las librer√≠as necesarias para el ajuste fino de modelos LLM (LLaMA‚ÄØ3, Qwen‚ÄØ2 y Foundation‚ÄëSec‚ÄØ8B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "476f95549e6b401b9370616071bc607e",
      "6bc14eae38cc40eb838abafc55d1983c",
      "200b696a0f1a4677a958f5c91fd805b6",
      "8f1f8f30b3174324b75376e3a79e9437",
      "78120bb2fdb04699974b274e73451d3d",
      "87dd2cbc35aa466bb2be4f790a93c7da",
      "d21abe7bfd6e49e290ad2a2d75cd2647",
      "bb460209c817488c9cbe2a19808d1533",
      "76a99312dce44408823c42da82395349",
      "8f3db173da764b43b7a8601350daaace",
      "98fd255c4fe74b8e8700f581c1a3a7e4",
      "9e5164264222422eb9abd0c3a764aa5b",
      "5d317d0c06c943038cae538b8f9d58a9",
      "a87e4f2a605c4de6870c7b1b60f25b94",
      "9ba4b78001fb4b96a7b4d3ac1fd365bf",
      "c01c5f523e21434da02cb5d0d4bd2325",
      "acc4e78815174a16856dc2a53c4c2d3b",
      "d0328880cdfc417bbdab3dd2e2696ccb",
      "ec365c2bd1ff43b9a7c1566ae4d43b98",
      "acbfa7f7b0d44f6daf9674230024b05a",
      "a031865116df469a9f1fa80ad2608b98",
      "d701dead592944c6bc86e64df785acc0",
      "a8e31f1991e9444fbcb15ef7f9e21eb0",
      "e80e88a8b4cb42fc9441649f673fa485",
      "62e3562aaa64423ab17967d218eb6066",
      "bf97b72f729c4d9ba019d76182ba7c0f",
      "f877027489f54aaea6746018aaf1ff5f",
      "21208c9566ed48088f44c69257391093",
      "01dfd2b84edd4d16a7091c7153b58e95",
      "7f6a9cebcf7f4f2e9ee63e213d3377dd",
      "8274b7457fb0472cb9a3a30413027e06",
      "4e8b2b4c9b8d4435a3c616c57899586a",
      "969ba9573c7b426cb282f2b771e2b360",
      "83ce2a2ec6b14b4d8f658eeb8fb3d64e",
      "379443d1b8584d40bec887586a2f847e",
      "8ef0bcdc185a469a969f4acb1be207fe",
      "2f7cde4e313547f9abcaf69e0c847464",
      "a4a94c53dc324c5fabd983133f2196a9",
      "bf1bfa7c05c949f49840567af208ed65",
      "e0ba5909c8384da7b15e8284cfce569c",
      "2d48394025024034b67573faa6777a5e",
      "640923045ce4499e96adfb92edd63a30",
      "c729d31ce49e4514afd3ab3f41c235b3",
      "2c87359666ca4acf8be0634efd3fa313",
      "71ddbce9d109498d94e9b9c8be4189f0",
      "04b49d88fca14b2c9bf8d5a79a05a741",
      "295f40838354467998c2767626d5466c",
      "ebb7259f4f7b405f82ace51f3cd2f402",
      "4184c21b51274624b625b944c98db5f7",
      "04924e2387084d6488f9d26efb77ba97",
      "b38386d1cfb34c73ba771d2e0d74e714",
      "5ea8978aa0a54cd09a8c592f108a94e3",
      "e445c948694247c3a6dff7dbe5659474",
      "5bfdd728ef984b6d8f828e7dd5360a2f",
      "b1a53451ac8b45659138e097fba92565",
      "d41f83483c8145589dcdcb207dd96d6a",
      "298f57bde96148c0ba0e169db46f6641",
      "03178850fb73437da32eb9fe0b3dcdf7",
      "870ad865c4914f50a751f9cc8bbbbcba",
      "8d84a116914d46a38763d5daaa39df67",
      "bf5b723b866944f1a69d906cb05fb097",
      "8fe13d77f1544770b5cc0c7d350e7b2e",
      "644e32b3b1c94e15beac0f2937b2a62b",
      "172bd8c4750c4b7192667bbe96e9eec8",
      "7c50a896e5c14897896663937f5215e0",
      "2a04fa1c675d480ca9592874e04c5de0",
      "7b721a25dbfb49888bbbfd1a9a57f690",
      "95781f309027437c838b5ec251c0eec0",
      "cd163e5624004caba17c033019ed5808",
      "73a18d3be1584bb7aba6e4d437e382c8",
      "2c0198936f1a4d73919d5abb4573e909",
      "fc03074824674ffbb81bdc34bb9c5053",
      "c65836e5e0144105bd3e33df90ba6219",
      "773ffaac097e437da9b8ab5eaf941e1b",
      "a9179cfa9580494d820daf6433e0f4c9",
      "9c11425959ae4b6dac2c9d507477e8b8",
      "f0b4e620bdf44e689e25d8863877676b",
      "2f629fe0e8694472864f329ddbee32fc",
      "5fb843b4409f4fec98e9e73a575ef40e",
      "175afcec86c24a2d8fe6a1ed3f00d920",
      "cc27f3368e8e42488d8c64ece2c415fb",
      "6ba56009d34f44b9ba3a8da99a312d35",
      "b576b1e141e94611907e1a26656a6108",
      "1974f7034adb4fabb5cf8fdc42063c31",
      "68833c5f5a414e81b550fa85e45c54d9",
      "40ebb628ef724ea1bd7bcf3b72d1a64b",
      "9af5674d9ba74a3f94847e21a3f3d4c8",
      "9aab3edac0f1490da1398278e0599782",
      "529b3f64a13c4b819cb511191c3108c7",
      "8fb1fbe1372f466daa361e2797f43324",
      "34ddd36e87964c4eb26359d51f88ba88",
      "6a110d8e46ae4131a58073bc90cd85e7",
      "a8d9715b00b44cb9b761a5b709363c1c",
      "6523357f667744d89ab0cf5e514281b6",
      "4d94bc29731845eba51fed753860099d",
      "071f486c12fe44f2926cc6e6bcff95ae",
      "dc622f2da1ab48cd9edda71d444e496b",
      "aed9de5285ee42f88e3a3518c12a5235",
      "9fc4d1b6465f42ee8bb3cb7fe5ca8948",
      "1329e923cc2145df850d91eade47029c",
      "564407e610414a4498b3036fcf396dad",
      "36b479b8e5e6425b8a86a2f779384437",
      "75a7cc290b6f409b8e5f87e2d51cc0a1",
      "5ea190623b924ca8bd77b0fcbcbcdf27",
      "bf09d87fcb3441689b516232f1341873",
      "3deb842c57d242778f76a340da635fb5",
      "68a577c2bde8413095d3b8adc588bd4a",
      "dca85b96c024451394f4ef3d8b13b81d",
      "b6021f5d74114b37ae438106ee0280a7",
      "d2dceea03d3d4414afe841d71ed62740",
      "174f8f2ffd454346b019d7577e70a029",
      "a3bb35a9202443c7940cac457f4b2f13",
      "43a1d203547841fab8be5fa38977adbb",
      "6e3c9bb7daf04d8bb365eab097e8a715",
      "d190e4446677476f8166daac81fc69c5",
      "c77c337f300e4aaba98bf765d8eed40c",
      "f2cd89bfb5fa40e096ff3b180631a9e0",
      "8efb563afca34065bf0cdf27d112dd15",
      "bb74969037ea411fbc2c700857c1531c",
      "7bdcf05bf8e240f4890c869e6e7ac71f",
      "5a6a16d2ef2c4113b4b7ff4636c7cede",
      "f0f95fd79123487cb5489596d03ad2f8",
      "52a90bf7576a4869a0fa4b19ca0a2802",
      "a28d67a33fa849febe8f02bf44d0591b",
      "138bb8a1815c4cf88f856137ba8159c9",
      "eefa946aa31b4ea396b4279d290cc70d",
      "37fcdb3da87e493b95890cb4b2c61c67",
      "479be208b1f244798b203e0761d99a8b",
      "d208c4f64f6846c69081662805d9e653",
      "45d7532d51734cbba2b4db548e2ccda2",
      "c59dde66968d4c5da739c4d25f3df0ba",
      "127858c900924aee8084d8f2ec1fcc2e",
      "d93e7190234d4488be239b90c1704854",
      "b5f27dacb3aa4a9db00282ec21c259c2",
      "cae2f4db9fbc41d7b8cd1e01855cd180",
      "349392c093384b26a602bc9f3ae6c54c",
      "cb9a46bc68b24cd79c4f00c26677ea3d",
      "ee13e7d8532b43efa882b3d19022f7f1",
      "58714ac2d8d543259b02703556a6dad8",
      "cd7035caff724a219427ee2ed1194336",
      "3de39396ac984d1d867dbf140389ce57",
      "56d7f6ea99974365bd75a8133e4149b7",
      "dd164647092a4ca19977182944866551",
      "b0bc7d8e40f4426d9293b9fa979bea71",
      "c35b11d885ac4a4d89416114460ef84a",
      "fd8807b57f894a4da10feaf1c36cbc59",
      "c38e73db3ca84891be5adf49f3a90cc0",
      "0537ecd144764a569ddde7305dc27942",
      "0d24267662b74e6bb3d1133c14a43dbf",
      "962a8611cad748cab567c4a4334943c3",
      "c615b540a4c541f2a3e15e2fe2e31853",
      "c65c975bb5b64ec5b4c722758a8d5bd8",
      "19b7b8a5c90c4ed2a7a8be409edea60a",
      "a26aebf534324d2e91491b896d507ee7",
      "a82dffbd91a442cf9a7155c9ecd3bec1",
      "d3b80d436bd34db88c0f4d61b58015c7",
      "ccb2859fe90f462fab3ebfe3bcb11f01",
      "0911459b93ac42c79e993f97c6b6b246",
      "c6a8e8e922494c55885f8f4da271c6b2",
      "ae2b8a1b3b014736a7c8eb0aa8114742",
      "32dbd79855cf40deadba81eeb53b7508",
      "f279560fbd044f028b3c7677419c5e39",
      "de08cf90f3e44286b014e6a7e3ed2d94",
      "1dd8b48f10464c3eb813eb6e6d3a7adf",
      "e7d1ddd28edf4f4ea6412a447252c5dd",
      "d80c2aa3cfc744d7b2c80cd5eeb556cf",
      "c9ec3a0bf8084d8cba211929dd2e5ca7",
      "a9b04b0990c4416d9f28f82b6064c313",
      "bc2d6105937248e8a2b0e02fe0f8dd1b",
      "7d76683f5b974fb4918aca95902d2965",
      "b47219e0700c4233b6d61e7fa7be97dc",
      "c44f0cf634f44e0590ca7a1d1007d7be",
      "a0f8f0fa7f6143cbbcb1e5990d1a0831",
      "4056dd2597154733b9a64fc14af06571",
      "167391660e594847a50c5c6fec1c01a7",
      "e48e7fffbece4f719ecdd114e798511b",
      "fefed12e3201411398a3cfc86c492fce",
      "e7181c9d70e84cb09882d122e79a21a6",
      "1f0297c26aa24d7dad239c1ea6adc38e",
      "a3f25872058e4f9aa13074fbc711c636",
      "0578d379b18b4a4385e238d59b35941e",
      "810dda179e4243c3aee8c6120f6dd70a",
      "36e10bafe8754505b6f6a909314b6d9e",
      "1227b9df63aa4c86baed876ffaadf597",
      "14d68fe4a63a4aaebdbbad29c23428f9",
      "f696b50939214e3884322e13037b945b",
      "6c482469c9974c66a353034eb908a8e1"
     ]
    },
    "executionInfo": {
     "elapsed": 1883445,
     "status": "ok",
     "timestamp": 1761001038044,
     "user": {
      "displayName": "Javier Moreno",
      "userId": "15898376622721324964"
     },
     "user_tz": 300
    },
    "id": "s6-DGfaRirlE",
    "outputId": "bfbc51c7-a7a7-47c3-a4b2-a3f03b08113e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ°Ô∏è Foundation-Sec-8B ‚Äî Entrenamiento 10k (A100, BF16, 4-bit, reproducible)\n",
      "============================================================================================\n",
      "‚ÑπÔ∏è Nota TFM: Se utiliza un subconjunto REPRESENTATIVO de 10 000 ejemplos para comparaci√≥n\n",
      "             justa y reproducible entre modelos (misma muestra, misma semilla).\n",
      "üíæ GPU inicial: 0.0/85.2 GB\n",
      "\n",
      "üì¶ Cargando dataset...\n",
      "‚úÖ Dataset cargado: 10,000 ejemplos (fijos, reproducibles)\n",
      "\n",
      "üì• Cargando modelo/tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476f95549e6b401b9370616071bc607e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/840 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5164264222422eb9abd0c3a764aa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e31f1991e9444fbcb15ef7f9e21eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ce2a2ec6b14b4d8f658eeb8fb3d64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ddbce9d109498d94e9b9c8be4189f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41f83483c8145589dcdcb207dd96d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b721a25dbfb49888bbbfd1a9a57f690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f629fe0e8694472864f329ddbee32fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529b3f64a13c4b819cb511191c3108c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1329e923cc2145df850d91eade47029c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174f8f2ffd454346b019d7577e70a029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f95fd79123487cb5489596d03ad2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93e7190234d4488be239b90c1704854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 524,288 || all params: 8,031,834,112 || trainable%: 0.0065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bc7d8e40f4426d9293b9fa979bea71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82dffbd91a442cf9a7155c9ecd3bec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80c2aa3cfc744d7b2c80cd5eeb556cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefed12e3201411398a3cfc86c492fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Entrenando Foundation-Sec-8B con 10 000 ejemplos (A100, reproducible)...\n",
      "üïê Inicio: 22:28:10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 29:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.946300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.738600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.714500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.524200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.381300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.325800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.321900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.307700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.300800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.305100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.290900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.291300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.292200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.287300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.295800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.286800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.284900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.284200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.286100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.284600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.280500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.283400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.280300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.285600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ ENTRENAMIENTO COMPLETADO\n",
      "   ‚è±Ô∏è Duraci√≥n: 29.1 min\n",
      "   üìâ Loss final: 0.454\n",
      "   ü™ú Steps: 2500\n",
      "\n",
      "üíæ Modelo guardado en: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/03_fine_tuning/foundation_sec_direct_10k/weights/foundation_sec_direct_10k_20251020_225716\n",
      "üßæ Resumen: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/03_fine_tuning/foundation_sec_direct_10k/foundation_sec_direct_10k_summary_20251020_225716.json\n",
      "\n",
      "üßπ Memoria liberada. Celda independiente completada.\n"
     ]
    }
   ],
   "source": [
    "# === FOUNDATION-SEC-8B: ENTRENAMIENTO DIRECTO 10 000 (A100, REPRODUCIBLE, CELDA INDEPENDIENTE) ===\n",
    "\"\"\"\n",
    "- Modelo: fdtn-ai/Foundation-Sec-8B-Instruct\n",
    "- T√©cnica: LoRA + 4-bit (NF4) con bitsandbytes\n",
    "- Dispositivo: A100 (BF16)\n",
    "- Reproducibilidad: semillas fijadas (random, numpy, torch, transformers.set_seed)\n",
    "- Celda independiente: instala deps, carga datos, entrena, guarda y limpia memoria.\n",
    "- Nota (TFM): Se usa un subconjunto REPRESENTATIVO de 10 000 ejemplos para comparaci√≥n justa entre LLMs.\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------\n",
    "# Instalaci√≥n r√°pida (celda independiente)\n",
    "# ----------------------------\n",
    "!pip install -q transformers peft trl datasets accelerate bitsandbytes\n",
    "\n",
    "# ----------------------------\n",
    "# Imports\n",
    "# ----------------------------\n",
    "import os, json, random, gc, numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from trl import SFTTrainer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibilidad (semillas fijas)\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "set_seed(SEED)  # reproducibilidad en Trainer/SFTTrainer\n",
    "\n",
    "print(\"üõ°Ô∏è Foundation-Sec-8B ‚Äî Entrenamiento 10k (A100, BF16, 4-bit, reproducible)\")\n",
    "print(\"=\" * 92)\n",
    "print(\"‚ÑπÔ∏è Nota TFM: Se utiliza un subconjunto REPRESENTATIVO de 10 000 ejemplos para comparaci√≥n\")\n",
    "print(\"             justa y reproducible entre modelos (misma muestra, misma semilla).\")\n",
    "\n",
    "# ----------------------------\n",
    "# Paths y configuraci√≥n\n",
    "# ----------------------------\n",
    "BASE_PATH = '/content/drive/MyDrive/TFM_CIC_Anomaly_Detection'\n",
    "OUT_PATH = f'{BASE_PATH}/03_fine_tuning/foundation_sec_direct_10k'\n",
    "os.makedirs(f'{OUT_PATH}/weights', exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"fdtn-ai/Foundation-Sec-8B-Instruct\"\n",
    "DATASET_FILE = f\"{BASE_PATH}/03_fine_tuning/dataset_preparation/validator_finetune_train_20251002_173852.jsonl\"\n",
    "DATASET_SIZE = 10_000  # fijo a 10k para comparabilidad\n",
    "\n",
    "# Hiperpar√°metros (alineados con LLaMA/Qwen)\n",
    "PER_DEVICE_BATCH = 2\n",
    "GRAD_ACC = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-5\n",
    "LOG_STEPS = 50\n",
    "SAVE_STEPS = 1000\n",
    "\n",
    "# ----------------------------\n",
    "# Verificaci√≥n de memoria (opcional)\n",
    "# ----------------------------\n",
    "if torch.cuda.is_available():\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "    print(f\"üíæ GPU inicial: {allocated:.1f}/{total_mem:.1f} GB\")\n",
    "\n",
    "# ----------------------------\n",
    "# Cargar dataset (primeros 10 000) y formatear prompts (plantilla estilo LLaMA)\n",
    "# ----------------------------\n",
    "print(\"\\nüì¶ Cargando dataset...\")\n",
    "with open(DATASET_FILE, 'r') as f:\n",
    "    full_data = [json.loads(line) for line in f]\n",
    "\n",
    "train_data = full_data[:DATASET_SIZE]\n",
    "print(f\"‚úÖ Dataset cargado: {len(train_data):,} ejemplos (fijos, reproducibles)\")\n",
    "\n",
    "def foundation_format(example):\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{example['system']}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{example['user']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{example['assistant']}<|eot_id|>\"\"\"\n",
    "\n",
    "formatted_texts = [foundation_format(ex) for ex in train_data]\n",
    "train_dataset = Dataset.from_dict({\"text\": formatted_texts})\n",
    "\n",
    "# ----------------------------\n",
    "# Cargar modelo/tokenizer (A100-friendly: BF16 + 4-bit NF4)\n",
    "# ----------------------------\n",
    "print(\"\\nüì• Cargando modelo/tokenizer...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # A100 ‚áí BF16\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,             # A100 ‚áí BF16\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ----------------------------\n",
    "# LoRA m√≠nima (id√©ntica entre LLMs)\n",
    "# ----------------------------\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=2,\n",
    "    lora_alpha=4,\n",
    "    target_modules=[\"q_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    inference_mode=False\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(base_model, lora_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "# (Opcional) m√°s memoria de activaciones si subes batch/seq:\n",
    "# peft_model.gradient_checkpointing_enable()\n",
    "\n",
    "# ----------------------------\n",
    "# TrainingArguments (alineados con LLaMA/Qwen)\n",
    "# ----------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{OUT_PATH}/checkpoints\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=PER_DEVICE_BATCH,\n",
    "    gradient_accumulation_steps=GRAD_ACC,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_steps=LOG_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    fp16=False,            # A100 ‚áí usar BF16\n",
    "    bf16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# SFTTrainer\n",
    "# ----------------------------\n",
    "trainer = SFTTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    formatting_func=lambda x: x[\"text\"]\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Entrenamiento\n",
    "# ----------------------------\n",
    "print(\"\\nüöÄ Entrenando Foundation-Sec-8B con 10 000 ejemplos (A100, reproducible)...\")\n",
    "start = datetime.now()\n",
    "print(f\"üïê Inicio: {start.strftime('%H:%M:%S')}\")\n",
    "\n",
    "result = trainer.train()\n",
    "\n",
    "end = datetime.now()\n",
    "dur_min = (end - start).total_seconds() / 60\n",
    "print(\"\\nüéâ ENTRENAMIENTO COMPLETADO\")\n",
    "print(f\"   ‚è±Ô∏è Duraci√≥n: {dur_min:.1f} min\")\n",
    "print(f\"   üìâ Loss final: {result.training_loss:.3f}\")\n",
    "print(f\"   ü™ú Steps: {result.global_step}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Guardado + resumen\n",
    "# ----------------------------\n",
    "timestamp = end.strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_path = f\"{OUT_PATH}/weights/foundation_sec_direct_10k_{timestamp}\"\n",
    "trainer.save_model(final_path)\n",
    "\n",
    "summary = {\n",
    "    \"timestamp\": end.isoformat(),\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"dataset_examples\": DATASET_SIZE,\n",
    "    \"final_loss\": float(result.training_loss),\n",
    "    \"duration_minutes\": float(dur_min),\n",
    "    \"per_device_batch\": PER_DEVICE_BATCH,\n",
    "    \"grad_acc\": GRAD_ACC,\n",
    "    \"precision\": \"bf16\",\n",
    "    \"seed\": SEED,\n",
    "    \"model_path\": final_path,\n",
    "    \"representative_subset_note\": \"Se usa subconjunto representativo de 10k para comparaci√≥n justa entre LLMs.\"\n",
    "}\n",
    "summary_path = f\"{OUT_PATH}/foundation_sec_direct_10k_summary_{timestamp}.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Modelo guardado en: {final_path}\")\n",
    "print(f\"üßæ Resumen: {summary_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Limpieza (para poder reiniciar/continuar otras celdas)\n",
    "# ----------------------------\n",
    "del trainer, peft_model, base_model, tokenizer, train_dataset, formatted_texts, train_data, full_data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nüßπ Memoria liberada. Celda independiente completada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vUIuwYb1fea"
   },
   "source": [
    "## Eval y M√©tricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importaci√≥n de dependencias y configuraci√≥n inicial.**\n",
    "\n",
    "Se instalan y cargan las librer√≠as necesarias para el ajuste fino de modelos LLM (LLaMA‚ÄØ3, Qwen‚ÄØ2 y Foundation‚ÄëSec‚ÄØ8B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 944
    },
    "executionInfo": {
     "elapsed": 2614,
     "status": "ok",
     "timestamp": 1761002952873,
     "user": {
      "displayName": "Javier Moreno",
      "userId": "15898376622721324964"
     },
     "user_tz": 300
    },
    "id": "NDQZ3FJ154GZ",
    "outputId": "daa7e168-3fe5-4a3f-e724-ff2f772597fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL detectados:\n",
      " - Foundation-Sec-8B-Instruct   | responses.jsonl      | size=3,501,099 | md5=a4dd3d699acaeb0f20a43c2ea11e72c1\n",
      " - Meta-Llama-3-8B-Instruct     | responses.jsonl      | size=3,127,358 | md5=302dc8848e4bc645d707e0a8c6dfdf50\n",
      " - Qwen1.5-7B-Chat              | responses.jsonl      | size=3,471,258 | md5=8b9c30b4f6ce53e00da1d0a01f6966d4\n",
      "\n",
      "== Peek (3 l√≠neas) por archivo ==\n",
      "\n",
      "[Foundation-Sec-8B-Instruct] responses.jsonl\n",
      "  {'model': 'fdtn-ai/Foundation-Sec-8B-Instruct', 'id': 'eval_10000', 'parsed_decision': 'CONFIRMED', 'pred': None, 'decision': None, 'validation': None}\n",
      "  {'model': 'fdtn-ai/Foundation-Sec-8B-Instruct', 'id': 'eval_10001', 'parsed_decision': 'CONFIRMED', 'pred': None, 'decision': None, 'validation': None}\n",
      "  {'model': 'fdtn-ai/Foundation-Sec-8B-Instruct', 'id': 'eval_10002', 'parsed_decision': 'CONFIRMED', 'pred': None, 'decision': None, 'validation': None}\n",
      "\n",
      "[Meta-Llama-3-8B-Instruct] responses.jsonl\n",
      "  {'model': 'meta-llama/Meta-Llama-3-8B-Instruct', 'id': 'eval_10000', 'parsed_decision': 'DISCARDED', 'pred': None, 'decision': None, 'validation': None}\n",
      "  {'model': 'meta-llama/Meta-Llama-3-8B-Instruct', 'id': 'eval_10001', 'parsed_decision': 'DISCARDED', 'pred': None, 'decision': None, 'validation': None}\n",
      "  {'model': 'meta-llama/Meta-Llama-3-8B-Instruct', 'id': 'eval_10002', 'parsed_decision': 'DISCARDED', 'pred': None, 'decision': None, 'validation': None}\n",
      "\n",
      "[Qwen1.5-7B-Chat] responses.jsonl\n",
      "  {'model': 'Qwen/Qwen1.5-7B-Chat', 'id': 'eval_10000', 'parsed_decision': 'CONFIRMED', 'pred': None, 'decision': None, 'validation': None}\n",
      "  {'model': 'Qwen/Qwen1.5-7B-Chat', 'id': 'eval_10001', 'parsed_decision': 'CONFIRMED', 'pred': None, 'decision': None, 'validation': None}\n",
      "  {'model': 'Qwen/Qwen1.5-7B-Chat', 'id': 'eval_10002', 'parsed_decision': 'CONFIRMED', 'pred': None, 'decision': None, 'validation': None}\n",
      "\n",
      "== Distribuci√≥n de labels por archivo ==\n",
      " Foundation-Sec-8B-Instruct   | responses.jsonl      | total=2,000 | {'CONFIRMED': 2000}\n",
      " Meta-Llama-3-8B-Instruct     | responses.jsonl      | total=2,000 | {'DISCARDED': 684, 'CONFIRMED': 980, 'INVALID_JSON': 336}\n",
      " Qwen1.5-7B-Chat              | responses.jsonl      | total=2,000 | {'CONFIRMED': 2000}\n",
      "\n",
      "Parseo completado ‚Üí registros en rango eval: 6,000\n",
      "Filtradas por falta de claves ‚Üí model:0, id:0, pred inv√°lido:336\n",
      "\n",
      "=== Tabla de m√©tricas (ordenada por MCC, F1, Balanced Acc.) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"meta-llama/Meta-Llama-3-8B-Instruct\",\n          \"Qwen/Qwen1.5-7B-Chat\",\n          \"fdtn-ai/Foundation-Sec-8B-Instruct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0496521231503078,\n        \"min\": 0.487,\n        \"max\": 0.573,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.573,\n          0.487\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precisi\\u00f3n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005022947341949736,\n        \"min\": 0.4015,\n        \"max\": 0.4102,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.4015,\n          0.4102\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23145972291812097,\n        \"min\": 0.5991,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.5991\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009814954576223639,\n        \"min\": 0.0,\n        \"max\": 0.017,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balanced Acc.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004907477288111791,\n        \"min\": 0.5,\n        \"max\": 0.5085,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.5085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009122134253196088,\n        \"min\": 0.0,\n        \"max\": 0.0158,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.0158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"JSON v\\u00e1lido (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.699484522385712,\n        \"min\": 83.2,\n        \"max\": 100.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100.0,\n          83.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2000,\n        \"max\": 2000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_valid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 193,\n        \"min\": 1664,\n        \"max\": 2000,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"coverage_valid_%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.699484522385712,\n        \"min\": 83.2,\n        \"max\": 100.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Confusion [TP,FN;FP,TN]\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LabelDist\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "metrics_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a83578a4-ac13-440f-b1b0-657f18ddbbf1\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precisi√≥n</th>\n",
       "      <th>Recall</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Balanced Acc.</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>JSON v√°lido (%)</th>\n",
       "      <th>n_eval</th>\n",
       "      <th>n_valid</th>\n",
       "      <th>coverage_valid_%</th>\n",
       "      <th>Confusion [TP,FN;FP,TN]</th>\n",
       "      <th>LabelDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5991</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>83.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>1664</td>\n",
       "      <td>83.2</td>\n",
       "      <td>[[402, 269], [578, 415]]</td>\n",
       "      <td>{'CONFIRMED': 980, 'DISCARDED': 684, 'INVALID_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen/Qwen1.5-7B-Chat</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[803, 0], [1197, 0]]</td>\n",
       "      <td>{'CONFIRMED': 2000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fdtn-ai/Foundation-Sec-8B-Instruct</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[803, 0], [1197, 0]]</td>\n",
       "      <td>{'CONFIRMED': 2000}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a83578a4-ac13-440f-b1b0-657f18ddbbf1')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a83578a4-ac13-440f-b1b0-657f18ddbbf1 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a83578a4-ac13-440f-b1b0-657f18ddbbf1');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-73a88670-ba33-4f83-8ae7-5ae2aa3c419c\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73a88670-ba33-4f83-8ae7-5ae2aa3c419c')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-73a88670-ba33-4f83-8ae7-5ae2aa3c419c button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_e368dee2-d998-43dc-8bf2-eb96eb32e892\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_e368dee2-d998-43dc-8bf2-eb96eb32e892 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('metrics_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                Modelo  F1-Score  Precisi√≥n  Recall    MCC  \\\n",
       "2  meta-llama/Meta-Llama-3-8B-Instruct     0.487     0.4102  0.5991  0.017   \n",
       "0                 Qwen/Qwen1.5-7B-Chat     0.573     0.4015  1.0000  0.000   \n",
       "1   fdtn-ai/Foundation-Sec-8B-Instruct     0.573     0.4015  1.0000  0.000   \n",
       "\n",
       "   Balanced Acc.   Kappa  JSON v√°lido (%)  n_eval  n_valid  coverage_valid_%  \\\n",
       "2         0.5085  0.0158             83.2    2000     1664              83.2   \n",
       "0         0.5000  0.0000            100.0    2000     2000             100.0   \n",
       "1         0.5000  0.0000            100.0    2000     2000             100.0   \n",
       "\n",
       "    Confusion [TP,FN;FP,TN]                                          LabelDist  \n",
       "2  [[402, 269], [578, 415]]  {'CONFIRMED': 980, 'DISCARDED': 684, 'INVALID_...  \n",
       "0     [[803, 0], [1197, 0]]                                {'CONFIRMED': 2000}  \n",
       "1     [[803, 0], [1197, 0]]                                {'CONFIRMED': 2000}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Guardado: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/comparison_results/run_20251015_175126/metrics_table_10k_with_json_posthoc_DIAGNOSTIC.csv | /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/comparison_results/run_20251015_175126/metrics_table_10k_with_json_posthoc_DIAGNOSTIC.json\n",
      "\n",
      "‚úÖ Integridad MD5: No se detectaron duplicados byte-a-byte entre los JSONL listados.\n",
      "‚úÖ Fin del diagn√≥stico.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Diagn√≥stico y M√©tricas Post-hoc (robusto)\n",
    "# - Verifica duplicados (MD5) de `responses.jsonl` por modelo.\n",
    "# - Inspecciona primeras l√≠neas y distribuci√≥n de labels por archivo.\n",
    "# - Normaliza alias de modelo (evita filas fantasma).\n",
    "# - Reconstruye m√©tricas en el split eval (eval_10000..eval_11999).\n",
    "# - Matriz de confusi√≥n etiquetada correctamente: [TP,FN;FP,TN].\n",
    "# - Reporta cobertura (n_eval, n_valid, % v√°lido) y guarda CSV/JSON paralelos.\n",
    "\n",
    "# %%\n",
    "import os, json, re, glob, hashlib, sys\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,\n",
    "    matthews_corrcoef, balanced_accuracy_score,\n",
    "    cohen_kappa_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Config (ajusta si cambia tu run)\n",
    "# -------------------------------\n",
    "BASE_PATH    = '/content/drive/MyDrive/TFM_CIC_Anomaly_Detection'\n",
    "RUN_DIR      = f\"{BASE_PATH}/02_baseline_colab/comparison_results/run_20251015_175126\"\n",
    "DATASET_FILE = f\"{BASE_PATH}/03_fine_tuning/dataset_preparation/validator_finetune_train_20251002_173852.jsonl\"\n",
    "\n",
    "EVAL_START = 10_000\n",
    "EVAL_SIZE  = 2_000\n",
    "EVAL_IDS   = {f\"eval_{EVAL_START+i}\" for i in range(EVAL_SIZE)}\n",
    "\n",
    "# -------------------------------\n",
    "# Utilidades\n",
    "# -------------------------------\n",
    "def md5sum(path: str) -> str:\n",
    "    h = hashlib.md5()\n",
    "    with open(path, 'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(1<<20), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def norm_label(x: str):\n",
    "    if x is None: return None\n",
    "    v = str(x).strip().upper()\n",
    "    if v in (\"CONFIRMAR\",\"CONFIRMADO\"):  v = \"CONFIRMED\"\n",
    "    if v in (\"DESCARTAR\",\"DESCARTADO\"):  v = \"DISCARDED\"\n",
    "    return v\n",
    "\n",
    "def extract_eval_id(any_id, fallback_counter=None):\n",
    "    \"\"\"Devuelve id tipo eval_XXXXX si es posible. Si viene FT_*, devuelve None.\"\"\"\n",
    "    if any_id is None:\n",
    "        return None\n",
    "    s = str(any_id)\n",
    "    if s.startswith(\"eval_\"):\n",
    "        return s\n",
    "    if s.isdigit() and fallback_counter is not None:\n",
    "        return f\"eval_{int(s)}\"\n",
    "    return None\n",
    "\n",
    "def norm_model_name(m: str) -> str:\n",
    "    if not m: return m\n",
    "    s = m.strip().lower()\n",
    "    # can√≥nicos:\n",
    "    if \"llama-3-8b\" in s or \"meta-llama-3-8b\" in s:\n",
    "        return \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "    if \"qwen1.5-7b\" in s or \"qwen-1.5-7b\" in s:\n",
    "        return \"Qwen/Qwen1.5-7B-Chat\"\n",
    "    if \"foundation-sec-8b\" in s or \"foundation sec 8b\" in s:\n",
    "        return \"fdtn-ai/Foundation-Sec-8B-Instruct\"\n",
    "    return m\n",
    "\n",
    "def get_decision(record: dict):\n",
    "    # prioridad de campos\n",
    "    for k in (\"parsed_decision\",\"pred\",\"decision\",\"validation\"):\n",
    "        if k in record and record[k] is not None:\n",
    "            return norm_label(record[k])\n",
    "    return \"INVALID_JSON\"\n",
    "\n",
    "def get_any_id(record: dict):\n",
    "    rid = record.get(\"id\") or record.get(\"sample_id\") or record.get(\"prompt_id\")\n",
    "    rid = extract_eval_id(rid)\n",
    "    if rid is None:\n",
    "        idx = record.get(\"id_idx\") or record.get(\"idx\")\n",
    "        rid = extract_eval_id(str(idx)) if idx is not None else None\n",
    "    return rid\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Listar artefactos por modelo\n",
    "# -------------------------------\n",
    "jsonl_files = []\n",
    "for mdir in sorted(os.listdir(RUN_DIR)):\n",
    "    sub = os.path.join(RUN_DIR, mdir)\n",
    "    if not os.path.isdir(sub):\n",
    "        continue\n",
    "    files = sorted(glob.glob(os.path.join(sub, \"*.jsonl\")))\n",
    "    for fp in files:\n",
    "        jsonl_files.append((mdir, fp))\n",
    "\n",
    "if not jsonl_files:\n",
    "    raise SystemExit(\"No se encontraron archivos *.jsonl en subcarpetas de RUN_DIR.\")\n",
    "\n",
    "print(\"JSONL detectados:\")\n",
    "for mdir, fp in jsonl_files:\n",
    "    try:\n",
    "        print(f\" - {mdir:28s} | {os.path.basename(fp):20s} | size={os.path.getsize(fp):,} | md5={md5sum(fp)}\")\n",
    "    except Exception as e:\n",
    "        print(f\" - {mdir:28s} | {os.path.basename(fp):20s} | <error md5: {e}>\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Inspecci√≥n: primeras l√≠neas y distribuci√≥n de labels\n",
    "# -------------------------------\n",
    "def peek_lines(path, n=3):\n",
    "    out = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= n: break\n",
    "            try:\n",
    "                r = json.loads(line)\n",
    "                out.append({\n",
    "                    \"model\": r.get(\"model\") or r.get(\"model_name\") or r.get(\"base_model\") or r.get(\"model_id\"),\n",
    "                    \"id\": r.get(\"id\") or r.get(\"sample_id\") or r.get(\"prompt_id\"),\n",
    "                    \"parsed_decision\": r.get(\"parsed_decision\"),\n",
    "                    \"pred\": r.get(\"pred\"),\n",
    "                    \"decision\": r.get(\"decision\"),\n",
    "                    \"validation\": r.get(\"validation\"),\n",
    "                })\n",
    "            except Exception as e:\n",
    "                out.append({\"_parse_error\": str(e), \"_raw\": line[:200]})\n",
    "    return out\n",
    "\n",
    "print(\"\\n== Peek (3 l√≠neas) por archivo ==\")\n",
    "for mdir, fp in jsonl_files:\n",
    "    print(f\"\\n[{mdir}] {os.path.basename(fp)}\")\n",
    "    for row in peek_lines(fp, n=3):\n",
    "        print(\" \", row)\n",
    "\n",
    "def label_distribution(path):\n",
    "    ctr = Counter()\n",
    "    total = 0\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                r = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            d = get_decision(r)\n",
    "            ctr[d] += 1\n",
    "            total += 1\n",
    "    return dict(ctr), total\n",
    "\n",
    "print(\"\\n== Distribuci√≥n de labels por archivo ==\")\n",
    "for mdir, fp in jsonl_files:\n",
    "    dist, tot = label_distribution(fp)\n",
    "    print(f\" {mdir:28s} | {os.path.basename(fp):20s} | total={tot:,} | {dist}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Cargar Ground Truth (eval)\n",
    "# -------------------------------\n",
    "with open(DATASET_FILE, \"r\") as f:\n",
    "    data = [json.loads(l) for l in f]\n",
    "eval_rows = data[EVAL_START:EVAL_START+EVAL_SIZE]\n",
    "gt_df = pd.DataFrame({\n",
    "    \"id\": [f\"eval_{EVAL_START+i}\" for i in range(len(eval_rows))],\n",
    "    \"gt\": [str(r.get(\"metadata\", {}).get(\"validation_gt\", \"UNKNOWN\")).upper() for r in eval_rows]\n",
    "})\n",
    "\n",
    "# -------------------------------\n",
    "# 4) Cargar predicciones (robusto)\n",
    "# -------------------------------\n",
    "records = []\n",
    "dup_md5_warn = []\n",
    "md5_by_fp = {}\n",
    "\n",
    "for mdir, fp in jsonl_files:\n",
    "    # md5 por archivo\n",
    "    try:\n",
    "        md5_by_fp[fp] = md5sum(fp)\n",
    "    except Exception:\n",
    "        md5_by_fp[fp] = \"<md5_error>\"\n",
    "\n",
    "# advertencia si hay md5 iguales (posible duplicado)\n",
    "md5_to_files = defaultdict(list)\n",
    "for fp, m in md5_by_fp.items():\n",
    "    md5_to_files[m].append(fp)\n",
    "dup_md5 = {m: fps for m, fps in md5_to_files.items() if m != \"<md5_error>\" and len(fps) > 1}\n",
    "if dup_md5:\n",
    "    print(\"\\n‚ö†Ô∏è Posibles duplicados por MD5:\")\n",
    "    for m, fps in dup_md5.items():\n",
    "        print(\"  md5:\", m)\n",
    "        for x in fps:\n",
    "            print(\"   ‚Ä¢\", x)\n",
    "    dup_md5_warn = [item for sub in dup_md5.values() for item in sub]\n",
    "\n",
    "# parseo de cada jsonl\n",
    "missing_model = missing_id = missing_pred = 0\n",
    "for mdir, fp in jsonl_files:\n",
    "    with open(fp, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                r = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            model = r.get(\"model\") or r.get(\"model_name\") or r.get(\"base_model\") or r.get(\"model_id\") or mdir\n",
    "            if not model:\n",
    "                missing_model += 1\n",
    "                continue\n",
    "            model = norm_model_name(model)\n",
    "\n",
    "            rid = get_any_id(r)\n",
    "            if rid is None:\n",
    "                missing_id += 1\n",
    "                continue\n",
    "\n",
    "            pred = get_decision(r)\n",
    "            if pred not in (\"CONFIRMED\",\"DISCARDED\"):\n",
    "                missing_pred += 1\n",
    "\n",
    "            # Filtramos al rango de evaluaci√≥n\n",
    "            if rid not in EVAL_IDS:\n",
    "                continue\n",
    "\n",
    "            records.append({\"id\": rid, \"model\": model, \"pred\": pred})\n",
    "\n",
    "print(f\"\\nParseo completado ‚Üí registros en rango eval: {len(records):,}\")\n",
    "print(f\"Filtradas por falta de claves ‚Üí model:{missing_model}, id:{missing_id}, pred inv√°lido:{missing_pred}\")\n",
    "\n",
    "preds_df = pd.DataFrame(records)\n",
    "if preds_df.empty:\n",
    "    raise RuntimeError(\"No hay predicciones v√°lidas en el rango eval (verifica RUN_DIR/DATASET_FILE).\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5) M√©tricas por modelo\n",
    "# -------------------------------\n",
    "def compute_metrics_for(sub_df: pd.DataFrame):\n",
    "    valid_mask = sub_df[\"pred\"].isin([\"CONFIRMED\",\"DISCARDED\"])\n",
    "    json_valid_pct = round(valid_mask.mean() * 100, 1)\n",
    "\n",
    "    metric_sub = sub_df[valid_mask & sub_df[\"gt\"].isin([\"CONFIRMED\",\"DISCARDED\"])].copy()\n",
    "    n_eval = len(sub_df)\n",
    "    n_valid = int(valid_mask.sum())\n",
    "\n",
    "    if metric_sub.empty:\n",
    "        return {\n",
    "            \"F1-Score\": 0, \"Precisi√≥n\": 0, \"Recall\": 0,\n",
    "            \"MCC\": 0, \"Balanced Acc.\": 0, \"Kappa\": 0,\n",
    "            \"JSON v√°lido (%)\": json_valid_pct,\n",
    "            \"n_eval\": n_eval, \"n_valid\": n_valid,\n",
    "            \"coverage_valid_%\": json_valid_pct,\n",
    "            \"Confusion [TP,FN;FP,TN]\": [[0,0],[0,0]]\n",
    "        }\n",
    "\n",
    "    y_true = metric_sub[\"gt\"].map({\"CONFIRMED\":1,\"DISCARDED\":0}).astype(int).to_numpy()\n",
    "    y_pred = metric_sub[\"pred\"].map({\"CONFIRMED\":1,\"DISCARDED\":0}).astype(int).to_numpy()\n",
    "\n",
    "    f1  = f1_score(y_true, y_pred)\n",
    "    pre = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    bal = balanced_accuracy_score(y_true, y_pred)\n",
    "    kap = cohen_kappa_score(y_true, y_pred)\n",
    "    # labels=[1,0] ‚Üí [[TP,FN],[FP,TN]]\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "\n",
    "    return {\n",
    "        \"F1-Score\": round(f1, 3),\n",
    "        \"Precisi√≥n\": round(pre, 4),\n",
    "        \"Recall\": round(rec, 4),\n",
    "        \"MCC\": round(mcc, 3),\n",
    "        \"Balanced Acc.\": round(bal, 4),\n",
    "        \"Kappa\": round(kap, 4),\n",
    "        \"JSON v√°lido (%)\": json_valid_pct,\n",
    "        \"n_eval\": n_eval,\n",
    "        \"n_valid\": n_valid,\n",
    "        \"coverage_valid_%\": json_valid_pct,\n",
    "        \"Confusion [TP,FN;FP,TN]\": cm.tolist()\n",
    "    }\n",
    "\n",
    "df = gt_df.merge(preds_df, on=\"id\", how=\"left\")\n",
    "\n",
    "rows = []\n",
    "for model in sorted(df[\"model\"].dropna().unique()):\n",
    "    sub = df[df[\"model\"] == model].copy()\n",
    "    met = compute_metrics_for(sub)\n",
    "    met[\"Modelo\"] = model\n",
    "    # distribuci√≥n por etiqueta para transparencia\n",
    "    lab_counts = sub[\"pred\"].value_counts(dropna=False).to_dict()\n",
    "    met[\"LabelDist\"] = {str(k): int(v) for k,v in lab_counts.items()}\n",
    "    rows.append(met)\n",
    "\n",
    "metrics_df = pd.DataFrame(rows).sort_values(\n",
    "    [\"MCC\",\"F1-Score\",\"Balanced Acc.\"],\n",
    "    ascending=False\n",
    ")[[\"Modelo\",\"F1-Score\",\"Precisi√≥n\",\"Recall\",\"MCC\",\"Balanced Acc.\",\"Kappa\",\n",
    "   \"JSON v√°lido (%)\",\"n_eval\",\"n_valid\",\"coverage_valid_%\",\"Confusion [TP,FN;FP,TN]\",\"LabelDist\"]]\n",
    "\n",
    "print(\"\\n=== Tabla de m√©tricas (ordenada por MCC, F1, Balanced Acc.) ===\")\n",
    "display(metrics_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 6) Guardado paralelo (diagn√≥stico)\n",
    "# -------------------------------\n",
    "csv_path  = os.path.join(RUN_DIR, \"metrics_table_10k_with_json_posthoc_DIAGNOSTIC.csv\")\n",
    "json_path = os.path.join(RUN_DIR, \"metrics_table_10k_with_json_posthoc_DIAGNOSTIC.json\")\n",
    "metrics_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(rows, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\nüíæ Guardado:\", csv_path, \"|\", json_path)\n",
    "\n",
    "# Se√±aliza claramente si detect√≥ duplicados por md5\n",
    "if dup_md5:\n",
    "    print(\"\\n‚ö†Ô∏è DETECCI√ìN: Hay artefactos con MD5 id√©ntico (posibles duplicados). Revisa arriba la secci√≥n 'Posibles duplicados por MD5'.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Integridad MD5: No se detectaron duplicados byte-a-byte entre los JSONL listados.\")\n",
    "\n",
    "print(\"‚úÖ Fin del diagn√≥stico.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importaci√≥n de dependencias y configuraci√≥n inicial.**\n",
    "\n",
    "Se instalan y cargan las librer√≠as necesarias para el ajuste fino de modelos LLM (LLaMA‚ÄØ3, Qwen‚ÄØ2 y Foundation‚ÄëSec‚ÄØ8B).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 1861,
     "status": "ok",
     "timestamp": 1761003154289,
     "user": {
      "displayName": "Javier Moreno",
      "userId": "15898376622721324964"
     },
     "user_tz": 300
    },
    "id": "WHARSfYY8dpm",
    "outputId": "e9f59f63-d597-4f83-f107-9ac83254d5d5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fdtn-ai/Foundation-Sec-8B-Instruct\",\n          \"Qwen/Qwen1.5-7B-Chat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.573,\n        \"max\": 0.573,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precisi\\u00f3n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.4015,\n        \"max\": 0.4015,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balanced Acc.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"JSON v\\u00e1lido (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 100.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2000,\n        \"max\": 2000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_valid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2000,\n        \"max\": 2000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Confusion [TP,FN;FP,TN]\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LabelDist\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "metrics_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-561e9bc9-eaa8-41b5-acea-ee0a95911c14\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precisi√≥n</th>\n",
       "      <th>Recall</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Balanced Acc.</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>JSON v√°lido (%)</th>\n",
       "      <th>n_eval</th>\n",
       "      <th>n_valid</th>\n",
       "      <th>Confusion [TP,FN;FP,TN]</th>\n",
       "      <th>LabelDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen/Qwen1.5-7B-Chat</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>[[803, 0], [1197, 0]]</td>\n",
       "      <td>{'CONFIRMED': 2000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fdtn-ai/Foundation-Sec-8B-Instruct</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>[[803, 0], [1197, 0]]</td>\n",
       "      <td>{'CONFIRMED': 2000}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-561e9bc9-eaa8-41b5-acea-ee0a95911c14')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-561e9bc9-eaa8-41b5-acea-ee0a95911c14 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-561e9bc9-eaa8-41b5-acea-ee0a95911c14');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-69693e8f-a8fc-46c5-8d57-cb72815d536e\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69693e8f-a8fc-46c5-8d57-cb72815d536e')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-69693e8f-a8fc-46c5-8d57-cb72815d536e button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_88bd3ac9-af56-459e-b849-67f382d5a090\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_88bd3ac9-af56-459e-b849-67f382d5a090 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('metrics_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                               Modelo  F1-Score  Precisi√≥n  Recall  MCC  \\\n",
       "0                Qwen/Qwen1.5-7B-Chat     0.573     0.4015     1.0  0.0   \n",
       "1  fdtn-ai/Foundation-Sec-8B-Instruct     0.573     0.4015     1.0  0.0   \n",
       "\n",
       "   Balanced Acc.  Kappa  JSON v√°lido (%)  n_eval  n_valid  \\\n",
       "0            0.5    0.0            100.0    2000     2000   \n",
       "1            0.5    0.0            100.0    2000     2000   \n",
       "\n",
       "  Confusion [TP,FN;FP,TN]            LabelDist  \n",
       "0   [[803, 0], [1197, 0]]  {'CONFIRMED': 2000}  \n",
       "1   [[803, 0], [1197, 0]]  {'CONFIRMED': 2000}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Guardado: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/comparison_results/run_20251015_175126/metrics_table_10k_reinfer_CHAT_PROMPT.csv | /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/comparison_results/run_20251015_175126/metrics_table_10k_reinfer_CHAT_PROMPT.json\n"
     ]
    }
   ],
   "source": [
    "# === Mostrar m√©tricas desde responses.jsonl (Qwen + Foundation) para eval_10000..11999 ===\n",
    "import os, json, re, pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, matthews_corrcoef, balanced_accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "BASE_PATH    = \"/content/drive/MyDrive/TFM_CIC_Anomaly_Detection\"\n",
    "RUN_DIR      = f\"{BASE_PATH}/02_baseline_colab/comparison_results/run_20251015_175126\"\n",
    "DATASET_FILE = f\"{BASE_PATH}/03_fine_tuning/dataset_preparation/validator_finetune_train_20251002_173852.jsonl\"\n",
    "EVAL_START, EVAL_SIZE = 10_000, 2_000\n",
    "EVAL_IDS = {f\"eval_{EVAL_START+i}\" for i in range(EVAL_SIZE)}\n",
    "\n",
    "def norm_label(x):\n",
    "    if x is None: return None\n",
    "    v = str(x).strip().upper()\n",
    "    if v in (\"CONFIRMAR\",\"CONFIRMADO\"): v = \"CONFIRMED\"\n",
    "    if v in (\"DESCARTAR\",\"DESCARTADO\"): v = \"DISCARDED\"\n",
    "    return v\n",
    "\n",
    "# GT\n",
    "with open(DATASET_FILE,\"r\") as f:\n",
    "    data = [json.loads(l) for l in f]\n",
    "eval_rows = data[EVAL_START:EVAL_START+EVAL_SIZE]\n",
    "gt_df = pd.DataFrame({\n",
    "    \"id\": [f\"eval_{EVAL_START+i}\" for i in range(len(eval_rows))],\n",
    "    \"gt\": [str(r.get(\"metadata\",{}).get(\"validation_gt\",\"UNKNOWN\")).upper() for r in eval_rows]\n",
    "})\n",
    "\n",
    "# Cargar preds desde responses.jsonl NUEVOS\n",
    "preds = []\n",
    "for repo, subdir in [\n",
    "    (\"Qwen/Qwen1.5-7B-Chat\", \"Qwen1.5-7B-Chat\"),\n",
    "    (\"fdtn-ai/Foundation-Sec-8B-Instruct\", \"Foundation-Sec-8B-Instruct\"),\n",
    "]:\n",
    "    fp = os.path.join(RUN_DIR, subdir, \"responses.jsonl\")\n",
    "    if not os.path.exists(fp):\n",
    "        print(f\"‚ö†Ô∏è No existe: {fp}\")\n",
    "        continue\n",
    "    with open(fp,\"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                r = json.loads(line)\n",
    "            except:\n",
    "                continue\n",
    "            rid = r.get(\"id\")\n",
    "            if rid not in EVAL_IDS:\n",
    "                continue\n",
    "            pred = norm_label(r.get(\"parsed_decision\"))\n",
    "            preds.append({\"id\": rid, \"model\": repo, \"pred\": pred})\n",
    "\n",
    "preds_df = pd.DataFrame(preds)\n",
    "if preds_df.empty:\n",
    "    raise RuntimeError(\"No se encontraron predicciones en el rango de evaluaci√≥n.\")\n",
    "\n",
    "# M√©tricas\n",
    "df = gt_df.merge(preds_df, on=\"id\", how=\"left\")\n",
    "rows = []\n",
    "for model in sorted(df[\"model\"].dropna().unique()):\n",
    "    sub = df[df[\"model\"]==model].copy()\n",
    "    valid_mask = sub[\"pred\"].isin([\"CONFIRMED\",\"DISCARDED\"])\n",
    "    metric_sub = sub[valid_mask & sub[\"gt\"].isin([\"CONFIRMED\",\"DISCARDED\"])].copy()\n",
    "    json_valid_pct = round(valid_mask.mean()*100,1)\n",
    "    n_eval, n_valid = len(sub), int(valid_mask.sum())\n",
    "    if metric_sub.empty:\n",
    "        rows.append({\"Modelo\":model,\"F1-Score\":0,\"Precisi√≥n\":0,\"Recall\":0,\"MCC\":0,\"Balanced Acc.\":0,\n",
    "                     \"Kappa\":0,\"JSON v√°lido (%)\":json_valid_pct,\"n_eval\":n_eval,\"n_valid\":n_valid,\n",
    "                     \"Confusion [TP,FN;FP,TN]\":[[0,0],[0,0]],\"LabelDist\":sub[\"pred\"].value_counts(dropna=False).to_dict()})\n",
    "        continue\n",
    "    y_true = metric_sub[\"gt\"].map({\"CONFIRMED\":1,\"DISCARDED\":0}).astype(int).to_numpy()\n",
    "    y_pred = metric_sub[\"pred\"].map({\"CONFIRMED\":1,\"DISCARDED\":0}).astype(int).to_numpy()\n",
    "    f1  = f1_score(y_true,y_pred); pre = precision_score(y_true,y_pred,zero_division=0)\n",
    "    rec = recall_score(y_true,y_pred,zero_division=0); mcc = matthews_corrcoef(y_true,y_pred)\n",
    "    bal = balanced_accuracy_score(y_true,y_pred); kap = cohen_kappa_score(y_true,y_pred)\n",
    "    cm  = confusion_matrix(y_true,y_pred,labels=[1,0])  # [[TP,FN],[FP,TN]]\n",
    "    rows.append({\n",
    "        \"Modelo\": model, \"F1-Score\": round(f1,3), \"Precisi√≥n\": round(pre,4), \"Recall\": round(rec,4),\n",
    "        \"MCC\": round(mcc,3), \"Balanced Acc.\": round(bal,4), \"Kappa\": round(kap,4),\n",
    "        \"JSON v√°lido (%)\": json_valid_pct, \"n_eval\": n_eval, \"n_valid\": n_valid,\n",
    "        \"Confusion [TP,FN;FP,TN]\": cm.tolist(),\n",
    "        \"LabelDist\": {str(k):int(v) for k,v in sub[\"pred\"].value_counts(dropna=False).to_dict().items()}\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(rows).sort_values([\"MCC\",\"F1-Score\",\"Balanced Acc.\"], ascending=False)\n",
    "from IPython.display import display\n",
    "display(metrics_df)\n",
    "\n",
    "# Guardar tambi√©n\n",
    "csv_path  = os.path.join(RUN_DIR, \"metrics_table_10k_reinfer_CHAT_PROMPT.csv\")\n",
    "json_path = os.path.join(RUN_DIR, \"metrics_table_10k_reinfer_CHAT_PROMPT.json\")\n",
    "metrics_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "with open(json_path,\"w\") as f:\n",
    "    json.dump(metrics_df.to_dict(orient=\"records\"), f, indent=2, ensure_ascii=False)\n",
    "print(\"üíæ Guardado:\", csv_path, \"|\", json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "84c0c7796e904d31b2087faf4fccc645",
      "e6e2d94eca824834a627cca4177cdbc3",
      "7364846706ce4319a6bdb1ea23da2b7d",
      "335ab3227c3a451cb687d94189a05585",
      "4fa3079deef146ae95258fbbfd2c8ff0",
      "474adcb248194341b6312383fae9627c",
      "d2c8f82593a448dfaf33db7d62b29017",
      "b0bff2b5389e4cbd849db3b2bbafe6ef",
      "64fc8ed5cf81427f84ea67140910e206",
      "a8a96ea29d194533ad47b2b7f17aff17",
      "1645289960e9486698ff948c23ce37fc",
      "94226aaa745141a59c85222268e6fe17",
      "89fd936f1b134d8c9aea5786ee0e116c",
      "7e1387acb48f46a490e2f71411433b19",
      "c9cf5c4286f24bcbba6071a660eaba4c",
      "67565d4dff724dde92943258124df516",
      "096499ababbb47d797bf07fecc131be0",
      "b36522b7f1c64da387d2e0896a06ddf9",
      "10938755da184402a02e3c5e5f9e48bd",
      "41d4e40fd2804f7db7f08ed72c0aa563",
      "b370cf4404f04ae7b35f0742fee9997f",
      "86fd7a71563e48fda19d8b6886073586"
     ]
    },
    "executionInfo": {
     "elapsed": 768896,
     "status": "ok",
     "timestamp": 1761004443267,
     "user": {
      "displayName": "Javier Moreno",
      "userId": "15898376622721324964"
     },
     "user_tz": 300
    },
    "id": "he_eX6fO-RRf",
    "outputId": "980c36aa-37ed-477c-a0d3-5cc1a768e1ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Inferencia determinista: Qwen/Qwen1.5-7B-Chat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c0c7796e904d31b2087faf4fccc645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ¬∑ 8/2000\n",
      "  ¬∑ 16/2000\n",
      "  ¬∑ 24/2000\n",
      "  ¬∑ 32/2000\n",
      "  ¬∑ 40/2000\n",
      "  ¬∑ 48/2000\n",
      "  ¬∑ 56/2000\n",
      "  ¬∑ 64/2000\n",
      "  ¬∑ 72/2000\n",
      "  ¬∑ 80/2000\n",
      "  ¬∑ 88/2000\n",
      "  ¬∑ 96/2000\n",
      "  ¬∑ 104/2000\n",
      "  ¬∑ 112/2000\n",
      "  ¬∑ 120/2000\n",
      "  ¬∑ 128/2000\n",
      "  ¬∑ 136/2000\n",
      "  ¬∑ 144/2000\n",
      "  ¬∑ 152/2000\n",
      "  ¬∑ 160/2000\n",
      "  ¬∑ 168/2000\n",
      "  ¬∑ 176/2000\n",
      "  ¬∑ 184/2000\n",
      "  ¬∑ 192/2000\n",
      "  ¬∑ 200/2000\n",
      "  ¬∑ 208/2000\n",
      "  ¬∑ 216/2000\n",
      "  ¬∑ 224/2000\n",
      "  ¬∑ 232/2000\n",
      "  ¬∑ 240/2000\n",
      "  ¬∑ 248/2000\n",
      "  ¬∑ 256/2000\n",
      "  ¬∑ 264/2000\n",
      "  ¬∑ 272/2000\n",
      "  ¬∑ 280/2000\n",
      "  ¬∑ 288/2000\n",
      "  ¬∑ 296/2000\n",
      "  ¬∑ 304/2000\n",
      "  ¬∑ 312/2000\n",
      "  ¬∑ 320/2000\n",
      "  ¬∑ 328/2000\n",
      "  ¬∑ 336/2000\n",
      "  ¬∑ 344/2000\n",
      "  ¬∑ 352/2000\n",
      "  ¬∑ 360/2000\n",
      "  ¬∑ 368/2000\n",
      "  ¬∑ 376/2000\n",
      "  ¬∑ 384/2000\n",
      "  ¬∑ 392/2000\n",
      "  ¬∑ 400/2000\n",
      "  ¬∑ 408/2000\n",
      "  ¬∑ 416/2000\n",
      "  ¬∑ 424/2000\n",
      "  ¬∑ 432/2000\n",
      "  ¬∑ 440/2000\n",
      "  ¬∑ 448/2000\n",
      "  ¬∑ 456/2000\n",
      "  ¬∑ 464/2000\n",
      "  ¬∑ 472/2000\n",
      "  ¬∑ 480/2000\n",
      "  ¬∑ 488/2000\n",
      "  ¬∑ 496/2000\n",
      "  ¬∑ 504/2000\n",
      "  ¬∑ 512/2000\n",
      "  ¬∑ 520/2000\n",
      "  ¬∑ 528/2000\n",
      "  ¬∑ 536/2000\n",
      "  ¬∑ 544/2000\n",
      "  ¬∑ 552/2000\n",
      "  ¬∑ 560/2000\n",
      "  ¬∑ 568/2000\n",
      "  ¬∑ 576/2000\n",
      "  ¬∑ 584/2000\n",
      "  ¬∑ 592/2000\n",
      "  ¬∑ 600/2000\n",
      "  ¬∑ 608/2000\n",
      "  ¬∑ 616/2000\n",
      "  ¬∑ 624/2000\n",
      "  ¬∑ 632/2000\n",
      "  ¬∑ 640/2000\n",
      "  ¬∑ 648/2000\n",
      "  ¬∑ 656/2000\n",
      "  ¬∑ 664/2000\n",
      "  ¬∑ 672/2000\n",
      "  ¬∑ 680/2000\n",
      "  ¬∑ 688/2000\n",
      "  ¬∑ 696/2000\n",
      "  ¬∑ 704/2000\n",
      "  ¬∑ 712/2000\n",
      "  ¬∑ 720/2000\n",
      "  ¬∑ 728/2000\n",
      "  ¬∑ 736/2000\n",
      "  ¬∑ 744/2000\n",
      "  ¬∑ 752/2000\n",
      "  ¬∑ 760/2000\n",
      "  ¬∑ 768/2000\n",
      "  ¬∑ 776/2000\n",
      "  ¬∑ 784/2000\n",
      "  ¬∑ 792/2000\n",
      "  ¬∑ 800/2000\n",
      "  ¬∑ 808/2000\n",
      "  ¬∑ 816/2000\n",
      "  ¬∑ 824/2000\n",
      "  ¬∑ 832/2000\n",
      "  ¬∑ 840/2000\n",
      "  ¬∑ 848/2000\n",
      "  ¬∑ 856/2000\n",
      "  ¬∑ 864/2000\n",
      "  ¬∑ 872/2000\n",
      "  ¬∑ 880/2000\n",
      "  ¬∑ 888/2000\n",
      "  ¬∑ 896/2000\n",
      "  ¬∑ 904/2000\n",
      "  ¬∑ 912/2000\n",
      "  ¬∑ 920/2000\n",
      "  ¬∑ 928/2000\n",
      "  ¬∑ 936/2000\n",
      "  ¬∑ 944/2000\n",
      "  ¬∑ 952/2000\n",
      "  ¬∑ 960/2000\n",
      "  ¬∑ 968/2000\n",
      "  ¬∑ 976/2000\n",
      "  ¬∑ 984/2000\n",
      "  ¬∑ 992/2000\n",
      "  ¬∑ 1000/2000\n",
      "  ¬∑ 1008/2000\n",
      "  ¬∑ 1016/2000\n",
      "  ¬∑ 1024/2000\n",
      "  ¬∑ 1032/2000\n",
      "  ¬∑ 1040/2000\n",
      "  ¬∑ 1048/2000\n",
      "  ¬∑ 1056/2000\n",
      "  ¬∑ 1064/2000\n",
      "  ¬∑ 1072/2000\n",
      "  ¬∑ 1080/2000\n",
      "  ¬∑ 1088/2000\n",
      "  ¬∑ 1096/2000\n",
      "  ¬∑ 1104/2000\n",
      "  ¬∑ 1112/2000\n",
      "  ¬∑ 1120/2000\n",
      "  ¬∑ 1128/2000\n",
      "  ¬∑ 1136/2000\n",
      "  ¬∑ 1144/2000\n",
      "  ¬∑ 1152/2000\n",
      "  ¬∑ 1160/2000\n",
      "  ¬∑ 1168/2000\n",
      "  ¬∑ 1176/2000\n",
      "  ¬∑ 1184/2000\n",
      "  ¬∑ 1192/2000\n",
      "  ¬∑ 1200/2000\n",
      "  ¬∑ 1208/2000\n",
      "  ¬∑ 1216/2000\n",
      "  ¬∑ 1224/2000\n",
      "  ¬∑ 1232/2000\n",
      "  ¬∑ 1240/2000\n",
      "  ¬∑ 1248/2000\n",
      "  ¬∑ 1256/2000\n",
      "  ¬∑ 1264/2000\n",
      "  ¬∑ 1272/2000\n",
      "  ¬∑ 1280/2000\n",
      "  ¬∑ 1288/2000\n",
      "  ¬∑ 1296/2000\n",
      "  ¬∑ 1304/2000\n",
      "  ¬∑ 1312/2000\n",
      "  ¬∑ 1320/2000\n",
      "  ¬∑ 1328/2000\n",
      "  ¬∑ 1336/2000\n",
      "  ¬∑ 1344/2000\n",
      "  ¬∑ 1352/2000\n",
      "  ¬∑ 1360/2000\n",
      "  ¬∑ 1368/2000\n",
      "  ¬∑ 1376/2000\n",
      "  ¬∑ 1384/2000\n",
      "  ¬∑ 1392/2000\n",
      "  ¬∑ 1400/2000\n",
      "  ¬∑ 1408/2000\n",
      "  ¬∑ 1416/2000\n",
      "  ¬∑ 1424/2000\n",
      "  ¬∑ 1432/2000\n",
      "  ¬∑ 1440/2000\n",
      "  ¬∑ 1448/2000\n",
      "  ¬∑ 1456/2000\n",
      "  ¬∑ 1464/2000\n",
      "  ¬∑ 1472/2000\n",
      "  ¬∑ 1480/2000\n",
      "  ¬∑ 1488/2000\n",
      "  ¬∑ 1496/2000\n",
      "  ¬∑ 1504/2000\n",
      "  ¬∑ 1512/2000\n",
      "  ¬∑ 1520/2000\n",
      "  ¬∑ 1528/2000\n",
      "  ¬∑ 1536/2000\n",
      "  ¬∑ 1544/2000\n",
      "  ¬∑ 1552/2000\n",
      "  ¬∑ 1560/2000\n",
      "  ¬∑ 1568/2000\n",
      "  ¬∑ 1576/2000\n",
      "  ¬∑ 1584/2000\n",
      "  ¬∑ 1592/2000\n",
      "  ¬∑ 1600/2000\n",
      "  ¬∑ 1608/2000\n",
      "  ¬∑ 1616/2000\n",
      "  ¬∑ 1624/2000\n",
      "  ¬∑ 1632/2000\n",
      "  ¬∑ 1640/2000\n",
      "  ¬∑ 1648/2000\n",
      "  ¬∑ 1656/2000\n",
      "  ¬∑ 1664/2000\n",
      "  ¬∑ 1672/2000\n",
      "  ¬∑ 1680/2000\n",
      "  ¬∑ 1688/2000\n",
      "  ¬∑ 1696/2000\n",
      "  ¬∑ 1704/2000\n",
      "  ¬∑ 1712/2000\n",
      "  ¬∑ 1720/2000\n",
      "  ¬∑ 1728/2000\n",
      "  ¬∑ 1736/2000\n",
      "  ¬∑ 1744/2000\n",
      "  ¬∑ 1752/2000\n",
      "  ¬∑ 1760/2000\n",
      "  ¬∑ 1768/2000\n",
      "  ¬∑ 1776/2000\n",
      "  ¬∑ 1784/2000\n",
      "  ¬∑ 1792/2000\n",
      "  ¬∑ 1800/2000\n",
      "  ¬∑ 1808/2000\n",
      "  ¬∑ 1816/2000\n",
      "  ¬∑ 1824/2000\n",
      "  ¬∑ 1832/2000\n",
      "  ¬∑ 1840/2000\n",
      "  ¬∑ 1848/2000\n",
      "  ¬∑ 1856/2000\n",
      "  ¬∑ 1864/2000\n",
      "  ¬∑ 1872/2000\n",
      "  ¬∑ 1880/2000\n",
      "  ¬∑ 1888/2000\n",
      "  ¬∑ 1896/2000\n",
      "  ¬∑ 1904/2000\n",
      "  ¬∑ 1912/2000\n",
      "  ¬∑ 1920/2000\n",
      "  ¬∑ 1928/2000\n",
      "  ¬∑ 1936/2000\n",
      "  ¬∑ 1944/2000\n",
      "  ¬∑ 1952/2000\n",
      "  ¬∑ 1960/2000\n",
      "  ¬∑ 1968/2000\n",
      "  ¬∑ 1976/2000\n",
      "  ¬∑ 1984/2000\n",
      "  ¬∑ 1992/2000\n",
      "  ¬∑ 2000/2000\n",
      "‚úÖ Guardado: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/comparison_results/run_20251015_175126/Qwen1.5-7B-Chat/responses.jsonl\n",
      "\n",
      "üîÅ Inferencia determinista: fdtn-ai/Foundation-Sec-8B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94226aaa745141a59c85222268e6fe17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ¬∑ 8/2000\n",
      "  ¬∑ 16/2000\n",
      "  ¬∑ 24/2000\n",
      "  ¬∑ 32/2000\n",
      "  ¬∑ 40/2000\n",
      "  ¬∑ 48/2000\n",
      "  ¬∑ 56/2000\n",
      "  ¬∑ 64/2000\n",
      "  ¬∑ 72/2000\n",
      "  ¬∑ 80/2000\n",
      "  ¬∑ 88/2000\n",
      "  ¬∑ 96/2000\n",
      "  ¬∑ 104/2000\n",
      "  ¬∑ 112/2000\n",
      "  ¬∑ 120/2000\n",
      "  ¬∑ 128/2000\n",
      "  ¬∑ 136/2000\n",
      "  ¬∑ 144/2000\n",
      "  ¬∑ 152/2000\n",
      "  ¬∑ 160/2000\n",
      "  ¬∑ 168/2000\n",
      "  ¬∑ 176/2000\n",
      "  ¬∑ 184/2000\n",
      "  ¬∑ 192/2000\n",
      "  ¬∑ 200/2000\n",
      "  ¬∑ 208/2000\n",
      "  ¬∑ 216/2000\n",
      "  ¬∑ 224/2000\n",
      "  ¬∑ 232/2000\n",
      "  ¬∑ 240/2000\n",
      "  ¬∑ 248/2000\n",
      "  ¬∑ 256/2000\n",
      "  ¬∑ 264/2000\n",
      "  ¬∑ 272/2000\n",
      "  ¬∑ 280/2000\n",
      "  ¬∑ 288/2000\n",
      "  ¬∑ 296/2000\n",
      "  ¬∑ 304/2000\n",
      "  ¬∑ 312/2000\n",
      "  ¬∑ 320/2000\n",
      "  ¬∑ 328/2000\n",
      "  ¬∑ 336/2000\n",
      "  ¬∑ 344/2000\n",
      "  ¬∑ 352/2000\n",
      "  ¬∑ 360/2000\n",
      "  ¬∑ 368/2000\n",
      "  ¬∑ 376/2000\n",
      "  ¬∑ 384/2000\n",
      "  ¬∑ 392/2000\n",
      "  ¬∑ 400/2000\n",
      "  ¬∑ 408/2000\n",
      "  ¬∑ 416/2000\n",
      "  ¬∑ 424/2000\n",
      "  ¬∑ 432/2000\n",
      "  ¬∑ 440/2000\n",
      "  ¬∑ 448/2000\n",
      "  ¬∑ 456/2000\n",
      "  ¬∑ 464/2000\n",
      "  ¬∑ 472/2000\n",
      "  ¬∑ 480/2000\n",
      "  ¬∑ 488/2000\n",
      "  ¬∑ 496/2000\n",
      "  ¬∑ 504/2000\n",
      "  ¬∑ 512/2000\n",
      "  ¬∑ 520/2000\n",
      "  ¬∑ 528/2000\n",
      "  ¬∑ 536/2000\n",
      "  ¬∑ 544/2000\n",
      "  ¬∑ 552/2000\n",
      "  ¬∑ 560/2000\n",
      "  ¬∑ 568/2000\n",
      "  ¬∑ 576/2000\n",
      "  ¬∑ 584/2000\n",
      "  ¬∑ 592/2000\n",
      "  ¬∑ 600/2000\n",
      "  ¬∑ 608/2000\n",
      "  ¬∑ 616/2000\n",
      "  ¬∑ 624/2000\n",
      "  ¬∑ 632/2000\n",
      "  ¬∑ 640/2000\n",
      "  ¬∑ 648/2000\n",
      "  ¬∑ 656/2000\n",
      "  ¬∑ 664/2000\n",
      "  ¬∑ 672/2000\n",
      "  ¬∑ 680/2000\n",
      "  ¬∑ 688/2000\n",
      "  ¬∑ 696/2000\n",
      "  ¬∑ 704/2000\n",
      "  ¬∑ 712/2000\n",
      "  ¬∑ 720/2000\n",
      "  ¬∑ 728/2000\n",
      "  ¬∑ 736/2000\n",
      "  ¬∑ 744/2000\n",
      "  ¬∑ 752/2000\n",
      "  ¬∑ 760/2000\n",
      "  ¬∑ 768/2000\n",
      "  ¬∑ 776/2000\n",
      "  ¬∑ 784/2000\n",
      "  ¬∑ 792/2000\n",
      "  ¬∑ 800/2000\n",
      "  ¬∑ 808/2000\n",
      "  ¬∑ 816/2000\n",
      "  ¬∑ 824/2000\n",
      "  ¬∑ 832/2000\n",
      "  ¬∑ 840/2000\n",
      "  ¬∑ 848/2000\n",
      "  ¬∑ 856/2000\n",
      "  ¬∑ 864/2000\n",
      "  ¬∑ 872/2000\n",
      "  ¬∑ 880/2000\n",
      "  ¬∑ 888/2000\n",
      "  ¬∑ 896/2000\n",
      "  ¬∑ 904/2000\n",
      "  ¬∑ 912/2000\n",
      "  ¬∑ 920/2000\n",
      "  ¬∑ 928/2000\n",
      "  ¬∑ 936/2000\n",
      "  ¬∑ 944/2000\n",
      "  ¬∑ 952/2000\n",
      "  ¬∑ 960/2000\n",
      "  ¬∑ 968/2000\n",
      "  ¬∑ 976/2000\n",
      "  ¬∑ 984/2000\n",
      "  ¬∑ 992/2000\n",
      "  ¬∑ 1000/2000\n",
      "  ¬∑ 1008/2000\n",
      "  ¬∑ 1016/2000\n",
      "  ¬∑ 1024/2000\n",
      "  ¬∑ 1032/2000\n",
      "  ¬∑ 1040/2000\n",
      "  ¬∑ 1048/2000\n",
      "  ¬∑ 1056/2000\n",
      "  ¬∑ 1064/2000\n",
      "  ¬∑ 1072/2000\n",
      "  ¬∑ 1080/2000\n",
      "  ¬∑ 1088/2000\n",
      "  ¬∑ 1096/2000\n",
      "  ¬∑ 1104/2000\n",
      "  ¬∑ 1112/2000\n",
      "  ¬∑ 1120/2000\n",
      "  ¬∑ 1128/2000\n",
      "  ¬∑ 1136/2000\n",
      "  ¬∑ 1144/2000\n",
      "  ¬∑ 1152/2000\n",
      "  ¬∑ 1160/2000\n",
      "  ¬∑ 1168/2000\n",
      "  ¬∑ 1176/2000\n",
      "  ¬∑ 1184/2000\n",
      "  ¬∑ 1192/2000\n",
      "  ¬∑ 1200/2000\n",
      "  ¬∑ 1208/2000\n",
      "  ¬∑ 1216/2000\n",
      "  ¬∑ 1224/2000\n",
      "  ¬∑ 1232/2000\n",
      "  ¬∑ 1240/2000\n",
      "  ¬∑ 1248/2000\n",
      "  ¬∑ 1256/2000\n",
      "  ¬∑ 1264/2000\n",
      "  ¬∑ 1272/2000\n",
      "  ¬∑ 1280/2000\n",
      "  ¬∑ 1288/2000\n",
      "  ¬∑ 1296/2000\n",
      "  ¬∑ 1304/2000\n",
      "  ¬∑ 1312/2000\n",
      "  ¬∑ 1320/2000\n",
      "  ¬∑ 1328/2000\n",
      "  ¬∑ 1336/2000\n",
      "  ¬∑ 1344/2000\n",
      "  ¬∑ 1352/2000\n",
      "  ¬∑ 1360/2000\n",
      "  ¬∑ 1368/2000\n",
      "  ¬∑ 1376/2000\n",
      "  ¬∑ 1384/2000\n",
      "  ¬∑ 1392/2000\n",
      "  ¬∑ 1400/2000\n",
      "  ¬∑ 1408/2000\n",
      "  ¬∑ 1416/2000\n",
      "  ¬∑ 1424/2000\n",
      "  ¬∑ 1432/2000\n",
      "  ¬∑ 1440/2000\n",
      "  ¬∑ 1448/2000\n",
      "  ¬∑ 1456/2000\n",
      "  ¬∑ 1464/2000\n",
      "  ¬∑ 1472/2000\n",
      "  ¬∑ 1480/2000\n",
      "  ¬∑ 1488/2000\n",
      "  ¬∑ 1496/2000\n",
      "  ¬∑ 1504/2000\n",
      "  ¬∑ 1512/2000\n",
      "  ¬∑ 1520/2000\n",
      "  ¬∑ 1528/2000\n",
      "  ¬∑ 1536/2000\n",
      "  ¬∑ 1544/2000\n",
      "  ¬∑ 1552/2000\n",
      "  ¬∑ 1560/2000\n",
      "  ¬∑ 1568/2000\n",
      "  ¬∑ 1576/2000\n",
      "  ¬∑ 1584/2000\n",
      "  ¬∑ 1592/2000\n",
      "  ¬∑ 1600/2000\n",
      "  ¬∑ 1608/2000\n",
      "  ¬∑ 1616/2000\n",
      "  ¬∑ 1624/2000\n",
      "  ¬∑ 1632/2000\n",
      "  ¬∑ 1640/2000\n",
      "  ¬∑ 1648/2000\n",
      "  ¬∑ 1656/2000\n",
      "  ¬∑ 1664/2000\n",
      "  ¬∑ 1672/2000\n",
      "  ¬∑ 1680/2000\n",
      "  ¬∑ 1688/2000\n",
      "  ¬∑ 1696/2000\n",
      "  ¬∑ 1704/2000\n",
      "  ¬∑ 1712/2000\n",
      "  ¬∑ 1720/2000\n",
      "  ¬∑ 1728/2000\n",
      "  ¬∑ 1736/2000\n",
      "  ¬∑ 1744/2000\n",
      "  ¬∑ 1752/2000\n",
      "  ¬∑ 1760/2000\n",
      "  ¬∑ 1768/2000\n",
      "  ¬∑ 1776/2000\n",
      "  ¬∑ 1784/2000\n",
      "  ¬∑ 1792/2000\n",
      "  ¬∑ 1800/2000\n",
      "  ¬∑ 1808/2000\n",
      "  ¬∑ 1816/2000\n",
      "  ¬∑ 1824/2000\n",
      "  ¬∑ 1832/2000\n",
      "  ¬∑ 1840/2000\n",
      "  ¬∑ 1848/2000\n",
      "  ¬∑ 1856/2000\n",
      "  ¬∑ 1864/2000\n",
      "  ¬∑ 1872/2000\n",
      "  ¬∑ 1880/2000\n",
      "  ¬∑ 1888/2000\n",
      "  ¬∑ 1896/2000\n",
      "  ¬∑ 1904/2000\n",
      "  ¬∑ 1912/2000\n",
      "  ¬∑ 1920/2000\n",
      "  ¬∑ 1928/2000\n",
      "  ¬∑ 1936/2000\n",
      "  ¬∑ 1944/2000\n",
      "  ¬∑ 1952/2000\n",
      "  ¬∑ 1960/2000\n",
      "  ¬∑ 1968/2000\n",
      "  ¬∑ 1976/2000\n",
      "  ¬∑ 1984/2000\n",
      "  ¬∑ 1992/2000\n",
      "  ¬∑ 2000/2000\n",
      "‚úÖ Guardado: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/comparison_results/run_20251015_175126/Foundation-Sec-8B-Instruct/responses.jsonl\n",
      "\n",
      "=== M√©tricas con FEW-SHOT + regla de incertidumbre ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fdtn-ai/Foundation-Sec-8B-Instruct\",\n          \"Qwen/Qwen1.5-7B-Chat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.573,\n        \"max\": 0.573,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precisi\\u00f3n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.4015,\n        \"max\": 0.4015,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balanced Acc.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"JSON v\\u00e1lido (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 100.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2000,\n        \"max\": 2000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_valid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2000,\n        \"max\": 2000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Confusion [TP,FN;FP,TN]\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LabelDist\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "metrics_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5c43f07d-b4ce-4c80-bf79-b242a18149f6\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precisi√≥n</th>\n",
       "      <th>Recall</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Balanced Acc.</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>JSON v√°lido (%)</th>\n",
       "      <th>n_eval</th>\n",
       "      <th>n_valid</th>\n",
       "      <th>Confusion [TP,FN;FP,TN]</th>\n",
       "      <th>LabelDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen/Qwen1.5-7B-Chat</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>[[803, 0], [1197, 0]]</td>\n",
       "      <td>{'CONFIRMED': 2000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fdtn-ai/Foundation-Sec-8B-Instruct</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>[[803, 0], [1197, 0]]</td>\n",
       "      <td>{'CONFIRMED': 2000}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c43f07d-b4ce-4c80-bf79-b242a18149f6')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5c43f07d-b4ce-4c80-bf79-b242a18149f6 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5c43f07d-b4ce-4c80-bf79-b242a18149f6');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-1178eb84-f5f2-4dca-89ac-fcd975d7fc6e\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1178eb84-f5f2-4dca-89ac-fcd975d7fc6e')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-1178eb84-f5f2-4dca-89ac-fcd975d7fc6e button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_32ed7e43-ab0d-462d-950a-ef882415a55c\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_32ed7e43-ab0d-462d-950a-ef882415a55c button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('metrics_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                               Modelo  F1-Score  Precisi√≥n  Recall  MCC  \\\n",
       "0                Qwen/Qwen1.5-7B-Chat     0.573     0.4015     1.0  0.0   \n",
       "1  fdtn-ai/Foundation-Sec-8B-Instruct     0.573     0.4015     1.0  0.0   \n",
       "\n",
       "   Balanced Acc.  Kappa  JSON v√°lido (%)  n_eval  n_valid  \\\n",
       "0            0.5    0.0            100.0    2000     2000   \n",
       "1            0.5    0.0            100.0    2000     2000   \n",
       "\n",
       "  Confusion [TP,FN;FP,TN]            LabelDist  \n",
       "0   [[803, 0], [1197, 0]]  {'CONFIRMED': 2000}  \n",
       "1   [[803, 0], [1197, 0]]  {'CONFIRMED': 2000}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Guardado: /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/comparison_results/run_20251015_175126/metrics_table_10k_reinfer_FEWSHOT.csv | /content/drive/MyDrive/TFM_CIC_Anomaly_Detection/02_baseline_colab/comparison_results/run_20251015_175126/metrics_table_10k_reinfer_FEWSHOT.json\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Re-inferencia 2k con FEW-SHOT balanceado + JSON estricto (Qwen & Foundation) y evaluaci√≥n\n",
    "\n",
    "# %%\n",
    "import os, json, re, gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, matthews_corrcoef, balanced_accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "BASE_PATH    = '/content/drive/MyDrive/TFM_CIC_Anomaly_Detection'\n",
    "RUN_DIR      = f\"{BASE_PATH}/02_baseline_colab/comparison_results/run_20251015_175126\"\n",
    "DATASET_FILE = f\"{BASE_PATH}/03_fine_tuning/dataset_preparation/validator_finetune_train_20251002_173852.jsonl\"\n",
    "EVAL_START, EVAL_SIZE = 10_000, 2_000\n",
    "EVAL_IDS = [f\"eval_{EVAL_START+i}\" for i in range(EVAL_SIZE)]\n",
    "\n",
    "MODELS = [\n",
    "    {\"repo\": \"Qwen/Qwen1.5-7B-Chat\", \"out_dir\": os.path.join(RUN_DIR, \"Qwen1.5-7B-Chat\"), \"trust_remote_code\": True},\n",
    "    {\"repo\": \"fdtn-ai/Foundation-Sec-8B-Instruct\", \"out_dir\": os.path.join(RUN_DIR, \"Foundation-Sec-8B-Instruct\"), \"trust_remote_code\": True},\n",
    "]\n",
    "for m in MODELS:\n",
    "    os.makedirs(m[\"out_dir\"], exist_ok=True)\n",
    "\n",
    "def norm_label(x):\n",
    "    if x is None: return None\n",
    "    v = str(x).strip().upper()\n",
    "    if v in (\"CONFIRMAR\",\"CONFIRMADO\"): v = \"CONFIRMED\"\n",
    "    if v in (\"DESCARTAR\",\"DESCARTADO\"): v = \"DISCARDED\"\n",
    "    return v\n",
    "\n",
    "def strict_parse_decision(text: str):\n",
    "    if not text: return None\n",
    "    # Intento JSON directo dentro del rango de llaves\n",
    "    m = re.search(r'\\{.*\\}', text, flags=re.S)\n",
    "    candidate = m.group(0) if m else text\n",
    "    try:\n",
    "        obj = json.loads(candidate)\n",
    "        dec = norm_label(obj.get(\"decision\"))\n",
    "        if dec in (\"CONFIRMED\",\"DISCARDED\"):\n",
    "            return dec\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = re.search(r'\"\\s*decision\\s*\"\\s*:\\s*\"(CONFIRMED|DISCARDED)\"', text, flags=re.I)\n",
    "    return m.group(1).upper() if m else None\n",
    "\n",
    "def load_eval_slice(dataset_file, start, size):\n",
    "    with open(dataset_file, \"r\") as f:\n",
    "        data = [json.loads(l) for l in f]\n",
    "    rows = data[start:start+size]\n",
    "    out = []\n",
    "    for i, r in enumerate(rows):\n",
    "        out.append({\n",
    "            \"id\": f\"eval_{start+i}\",\n",
    "            \"system\": r.get(\"system\",\"\"),\n",
    "            \"user\":   r.get(\"user\",\"\"),\n",
    "            \"gt\":     str(r.get(\"metadata\",{}).get(\"validation_gt\",\"UNKNOWN\")).upper()\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def bnb4bit_config():\n",
    "    return BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "\n",
    "# ---- FEW-SHOT: 1 DISCARDED + 1 CONFIRMED (plantillas neutrales) ----\n",
    "FS_NEG_USER = \"Contexto: la alerta no tiene evidencia corroborable y contradice los logs principales.\"\n",
    "FS_NEG_ASSI = '{ \"decision\": \"DISCARDED\" }'\n",
    "FS_POS_USER = \"Contexto: la alerta coincide con varios indicadores y el impacto est√° confirmado en m√∫ltiples fuentes.\"\n",
    "FS_POS_ASSI = '{ \"decision\": \"CONFIRMED\" }'\n",
    "\n",
    "def build_messages(system_ctx: str, user_ctx: str):\n",
    "    policy = (\n",
    "        \"Eres un validador binario. Devuelve EXCLUSIVAMENTE JSON v√°lido con el esquema exacto:\\n\"\n",
    "        '{ \"decision\": \"CONFIRMED\" }  o  { \"decision\": \"DISCARDED\" }.\\n'\n",
    "        \"Si la evidencia es ambigua o insuficiente, responde { \\\"decision\\\": \\\"DISCARDED\\\" }.\\n\"\n",
    "        \"No incluyas texto adicional.\"\n",
    "    )\n",
    "    sys = (system_ctx or \"\").strip()\n",
    "    sys = (sys + \"\\n\\n\" + policy) if sys else policy\n",
    "    msgs = [\n",
    "        {\"role\":\"system\",\"content\": sys},\n",
    "        {\"role\":\"user\",     \"content\": FS_NEG_USER},\n",
    "        {\"role\":\"assistant\",\"content\": FS_NEG_ASSI},\n",
    "        {\"role\":\"user\",     \"content\": FS_POS_USER},\n",
    "        {\"role\":\"assistant\",\"content\": FS_POS_ASSI},\n",
    "        {\"role\":\"user\",     \"content\": (user_ctx or \"\").strip()},\n",
    "    ]\n",
    "    return msgs\n",
    "\n",
    "def infer_model(repo, out_dir, eval_items, trust_remote_code=True, batch_size=8, max_new_tokens=32):\n",
    "    print(f\"\\nüîÅ Inferencia determinista: {repo}\")\n",
    "    quant = bnb4bit_config()\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        repo, quantization_config=quant,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
    "        device_map=\"auto\", trust_remote_code=trust_remote_code, low_cpu_mem_usage=True\n",
    "    )\n",
    "    tok = AutoTokenizer.from_pretrained(repo, trust_remote_code=True)\n",
    "    tok.padding_side = \"left\"     # <-- clave para decoder-only\n",
    "    if tok.pad_token is None and tok.eos_token is not None:\n",
    "        tok.pad_token = tok.eos_token\n",
    "\n",
    "    out_path = os.path.join(out_dir, \"responses.jsonl\")\n",
    "    with open(out_path, \"w\"): pass\n",
    "\n",
    "    total = len(eval_items)\n",
    "    for beg in range(0, total, batch_size):\n",
    "        chunk = eval_items[beg:beg+batch_size]\n",
    "        texts, ids = [], []\n",
    "        for ex in chunk:\n",
    "            msgs = build_messages(ex[\"system\"], ex[\"user\"])\n",
    "            txt  = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "            texts.append(txt); ids.append(ex[\"id\"])\n",
    "        enc = tok(texts, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            gen = model.generate(\n",
    "                **enc, max_new_tokens=max_new_tokens,\n",
    "                do_sample=False, temperature=0.0, top_p=1.0,\n",
    "                pad_token_id=tok.pad_token_id\n",
    "            )\n",
    "        outs = tok.batch_decode(gen, skip_special_tokens=True)\n",
    "        with open(out_path, \"a\") as f:\n",
    "            for eid, raw in zip(ids, outs):\n",
    "                parsed = strict_parse_decision(raw)\n",
    "                f.write(json.dumps({\"id\":eid,\"model\":repo,\"parsed_decision\":parsed,\"raw_output\":raw}, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"  ¬∑ {min(beg+batch_size,total)}/{total}\")\n",
    "    del model, tok\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    print(\"‚úÖ Guardado:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "# ---- 1) Carga eval + 2) Inferencia ----\n",
    "eval_items = load_eval_slice(DATASET_FILE, EVAL_START, EVAL_SIZE)\n",
    "gt_df = pd.DataFrame({\"id\":[x[\"id\"] for x in eval_items], \"gt\":[x[\"gt\"] for x in eval_items]})\n",
    "\n",
    "paths = []\n",
    "for cfg in MODELS:\n",
    "    paths.append((cfg[\"repo\"], infer_model(cfg[\"repo\"], cfg[\"out_dir\"], eval_items, cfg[\"trust_remote_code\"], batch_size=8, max_new_tokens=32)))\n",
    "\n",
    "# ---- 3) Evaluaci√≥n ----\n",
    "def compute_metrics(gt_df, preds_df):\n",
    "    df = gt_df.merge(preds_df, on=\"id\", how=\"left\")\n",
    "    rows=[]\n",
    "    for model in sorted(df[\"model\"].dropna().unique()):\n",
    "        sub = df[df[\"model\"]==model].copy()\n",
    "        valid = sub[\"pred\"].isin([\"CONFIRMED\",\"DISCARDED\"])\n",
    "        n_eval, n_valid = len(sub), int(valid.sum())\n",
    "        json_valid_pct = round(100.0*valid.mean(),1)\n",
    "        metric_sub = sub[valid & sub[\"gt\"].isin([\"CONFIRMED\",\"DISCARDED\"])]\n",
    "        if metric_sub.empty:\n",
    "            rows.append({\"Modelo\":model,\"F1-Score\":0,\"Precisi√≥n\":0,\"Recall\":0,\"MCC\":0,\"Balanced Acc.\":0,\n",
    "                         \"Kappa\":0,\"JSON v√°lido (%)\":json_valid_pct,\"n_eval\":n_eval,\"n_valid\":n_valid,\n",
    "                         \"Confusion [TP,FN;FP,TN]\":[[0,0],[0,0]],\"LabelDist\":sub[\"pred\"].value_counts(dropna=False).to_dict()})\n",
    "            continue\n",
    "        y_true = metric_sub[\"gt\"].map({\"CONFIRMED\":1,\"DISCARDED\":0}).astype(int).to_numpy()\n",
    "        y_pred = metric_sub[\"pred\"].map({\"CONFIRMED\":1,\"DISCARDED\":0}).astype(int).to_numpy()\n",
    "        f1  = f1_score(y_true,y_pred); pre = precision_score(y_true,y_pred,zero_division=0)\n",
    "        rec = recall_score(y_true,y_pred,zero_division=0); mcc = matthews_corrcoef(y_true,y_pred)\n",
    "        bal = balanced_accuracy_score(y_true,y_pred); kap = cohen_kappa_score(y_true,y_pred)\n",
    "        cm  = confusion_matrix(y_true,y_pred,labels=[1,0])  # [[TP,FN],[FP,TN]]\n",
    "        rows.append({\n",
    "            \"Modelo\": model, \"F1-Score\": round(f1,3), \"Precisi√≥n\": round(pre,4), \"Recall\": round(rec,4),\n",
    "            \"MCC\": round(mcc,3), \"Balanced Acc.\": round(bal,4), \"Kappa\": round(kap,4),\n",
    "            \"JSON v√°lido (%)\": json_valid_pct, \"n_eval\": n_eval, \"n_valid\": n_valid,\n",
    "            \"Confusion [TP,FN;FP,TN]\": cm.tolist(),\n",
    "            \"LabelDist\": {str(k):int(v) for k,v in sub[\"pred\"].value_counts(dropna=False).to_dict().items()}\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values([\"MCC\",\"F1-Score\",\"Balanced Acc.\"], ascending=False)\n",
    "\n",
    "# cargar preds reci√©n generadas\n",
    "preds = []\n",
    "for repo, fp in paths:\n",
    "    with open(fp,\"r\") as f:\n",
    "        for line in f:\n",
    "            try: r = json.loads(line)\n",
    "            except: continue\n",
    "            if r.get(\"id\") in set(EVAL_IDS):\n",
    "                preds.append({\"id\": r[\"id\"], \"model\": repo, \"pred\": norm_label(r.get(\"parsed_decision\"))})\n",
    "preds_df = pd.DataFrame(preds)\n",
    "if preds_df.empty: raise RuntimeError(\"Sin predicciones v√°lidas. Revisa inferencia.\")\n",
    "metrics_df = compute_metrics(gt_df, preds_df)\n",
    "\n",
    "from IPython.display import display\n",
    "print(\"\\n=== M√©tricas con FEW-SHOT + regla de incertidumbre ===\")\n",
    "display(metrics_df)\n",
    "\n",
    "csv_path = os.path.join(RUN_DIR, \"metrics_table_10k_reinfer_FEWSHOT.csv\")\n",
    "json_path = os.path.join(RUN_DIR, \"metrics_table_10k_reinfer_FEWSHOT.json\")\n",
    "metrics_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "with open(json_path,\"w\") as f: json.dump(metrics_df.to_dict(orient=\"records\"), f, indent=2, ensure_ascii=False)\n",
    "print(\"üíæ Guardado:\", csv_path, \"|\", json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLaMA-3-8B</td>\n",
       "      <td>402</td>\n",
       "      <td>415</td>\n",
       "      <td>578</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen-1.5-7B</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>1197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Foundation-Sec-8B</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>1197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Modelo   TP   TN    FP   FN\n",
       "0         LLaMA-3-8B  402  415   578  269\n",
       "1        Qwen-1.5-7B  803    0  1197    0\n",
       "2  Foundation-Sec-8B  803    0  1197    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javimore/Documents/Virtualenv/viupyforai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/Users/javimore/Documents/Virtualenv/viupyforai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precisi√≥n</th>\n",
       "      <th>Recall</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Balanced Acc.</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLaMA-3-8B</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.5991</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen-1.5-7B</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Foundation-Sec-8B</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4015</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Modelo  F1-Score  Precisi√≥n  Recall    MCC  Balanced Acc.  \\\n",
       "0         LLaMA-3-8B     0.487     0.5991  0.4102  0.017         0.5085   \n",
       "1        Qwen-1.5-7B     0.573     1.0000  0.4015  0.000         0.4015   \n",
       "2  Foundation-Sec-8B     0.573     1.0000  0.4015  0.000         0.4015   \n",
       "\n",
       "    Kappa  \n",
       "0  0.0158  \n",
       "1  0.0000  \n",
       "2  0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Imagen guardada en: ./run_20251015_175126/confusion_matrices_viz.png\n",
      "üíæ CSV de m√©tricas guardado en: ./run_20251015_175126/metrics_from_confusion.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# üìä Matrices de confusi√≥n y m√©tricas derivadas por modelo (TP, TN, FP, FN)\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,\n",
    "    matthews_corrcoef, balanced_accuracy_score, cohen_kappa_score\n",
    ")\n",
    "\n",
    "# === Datos base (Tabla 13) ===\n",
    "data = [\n",
    "    [\"LLaMA-3-8B\", 402, 415, 578, 269],\n",
    "    [\"Qwen-1.5-7B\", 803, 0, 1197, 0],\n",
    "    [\"Foundation-Sec-8B\", 803, 0, 1197, 0],\n",
    "]\n",
    "df = pd.DataFrame(data, columns=[\"Modelo\", \"TP\", \"TN\", \"FP\", \"FN\"])\n",
    "display(df)\n",
    "\n",
    "# === Calcular m√©tricas ===\n",
    "metric_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    TP, TN, FP, FN = row[\"TP\"], row[\"TN\"], row[\"FP\"], row[\"FN\"]\n",
    "    model = row[\"Modelo\"]\n",
    "\n",
    "    # Reconstruir vectores binarios simulados\n",
    "    y_true = np.array([1]*TP + [0]*FN + [1]*FP + [0]*TN)\n",
    "    y_pred = np.array([1]*TP + [1]*FN + [0]*FP + [0]*TN)\n",
    "\n",
    "    f1  = f1_score(y_true, y_pred, zero_division=0)\n",
    "    pre = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    bal = balanced_accuracy_score(y_true, y_pred)\n",
    "    kap = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "    metric_rows.append({\n",
    "        \"Modelo\": model,\n",
    "        \"F1-Score\": round(f1, 3),\n",
    "        \"Precisi√≥n\": round(pre, 4),\n",
    "        \"Recall\": round(rec, 4),\n",
    "        \"MCC\": round(mcc, 3),\n",
    "        \"Balanced Acc.\": round(bal, 4),\n",
    "        \"Kappa\": round(kap, 4)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metric_rows)\n",
    "display(metrics_df)\n",
    "\n",
    "# === Visualizaci√≥n de matrices de confusi√≥n ===\n",
    "matrices = {}\n",
    "for _, row in df.iterrows():\n",
    "    model = row[\"Modelo\"]\n",
    "    cm = np.array([[row[\"TP\"], row[\"FN\"]],\n",
    "                   [row[\"FP\"], row[\"TN\"]]])\n",
    "    matrices[model] = cm\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for ax, (model, cm) in zip(axes, matrices.items()):\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax,\n",
    "                xticklabels=[\"Pred: CONFIRMED\", \"Pred: DISCARDED\"],\n",
    "                yticklabels=[\"GT: CONFIRMED\", \"GT: DISCARDED\"])\n",
    "    ax.set_title(model)\n",
    "plt.suptitle(\"Matrices de confusi√≥n por modelo (TP, TN, FP, FN)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Guardar resultados ===\n",
    "# RUN_DIR = \"./run_20251015_175126\"\n",
    "# img_path = os.path.join(RUN_DIR, \"confusion_matrices_viz.png\")\n",
    "# csv_path = os.path.join(RUN_DIR, \"metrics_from_confusion.csv\")\n",
    "# metrics_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "# fig.savefig(img_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(f\"üíæ Imagen guardada en: {img_path}\")\n",
    "print(f\"üíæ CSV de m√©tricas guardado en: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Celda auxiliar o de soporte.**\n",
    "\n",
    "Ejecuci√≥n complementaria necesaria para el flujo general del experimento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo determinar la ruta autom√°ticamente. Por favor, introduce la ruta completa de tu notebook:\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "import os\n",
    "from IPython import get_ipython\n",
    "\n",
    "def remove_widgets_metadata():\n",
    "    # Obtener la ruta del notebook actual\n",
    "    # Esto funciona tanto en Jupyter Lab/Notebook como en Google Colab\n",
    "    try:\n",
    "        # Para Jupyter Lab/Notebook\n",
    "        notebook_path = get_ipython().config['FileContentsManager']['root_dir'] + '/' + get_ipython().config['FileContentsManager']['path']\n",
    "    except Exception:\n",
    "        # Para Google Colab (asume que est√°s en el directorio de trabajo actual)\n",
    "        # Si el notebook est√° en Google Drive, aseg√∫rate de que Drive est√© montado\n",
    "        # y que el notebook est√© en el directorio actual o proporciona la ruta completa.\n",
    "        # Por ejemplo, si el notebook se llama \"MiNotebook.ipynb\" y est√° en /content/\n",
    "        # puedes usar: notebook_path = \"MiNotebook.ipynb\"\n",
    "        # O si est√° en Drive montado: notebook_path = \"/content/drive/MyDrive/MiCarpeta/MiNotebook.ipynb\"\n",
    "        \n",
    "        # Una forma m√°s robusta para Colab es obtener el nombre del archivo actual\n",
    "        # y asumir que est√° en el directorio actual o donde lo hayas guardado.\n",
    "        # Para simplificar, si no est√°s seguro, puedes reemplazar la siguiente l√≠nea\n",
    "        # con la ruta completa a tu archivo .ipynb\n",
    "        print(\"No se pudo determinar la ruta autom√°ticamente. Por favor, introduce la ruta completa de tu notebook:\")\n",
    "        notebook_path = input(\"Ruta del notebook (ej: /content/MiNotebook.ipynb): \")\n",
    "        if not os.path.exists(notebook_path):\n",
    "            print(f\"Error: El archivo '{notebook_path}' no existe. Por favor, verifica la ruta.\")\n",
    "            return\n",
    "\n",
    "    print(f\"Intentando procesar el notebook: {notebook_path}\")\n",
    "\n",
    "    # Cargar el notebook\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Verificar y eliminar el bloque 'widgets' si existe\n",
    "    if 'metadata' in notebook_content and 'widgets' in notebook_content['metadata']:\n",
    "        print(\"Se encontr√≥ el bloque 'metadata.widgets'. Eliminando...\")\n",
    "        del notebook_content['metadata']['widgets']\n",
    "        print(\"Bloque 'metadata.widgets' eliminado.\")\n",
    "        \n",
    "        # Guardar el notebook modificado\n",
    "        with open(notebook_path, 'w', encoding='utf-8') as f:\n",
    "            nbformat.write(notebook_content, f)\n",
    "        print(\"Notebook guardado exitosamente sin el bloque 'metadata.widgets'.\")\n",
    "        print(\"Ahora puedes descargar este archivo y subirlo a GitHub.\")\n",
    "    else:\n",
    "        print(\"El bloque 'metadata.widgets' no se encontr√≥ o ya ha sido eliminado. El notebook ya deber√≠a ser compatible con GitHub.\")\n",
    "\n",
    "# Ejecutar la funci√≥n\n",
    "remove_widgets_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNSQJ58Zdbcn3Yq3tva2VoF",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
